{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# For time series analysis\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from prophet import Prophet\n",
    "\n",
    "# For machine learning\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, IsolationForest\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2024-03-19 21:54:00\n",
      "1        2024-03-19 18:59:00\n",
      "2        2024-03-19 00:14:00\n",
      "3        2024-03-19 18:19:00\n",
      "4        2024-03-19 15:03:00\n",
      "                 ...        \n",
      "367069   2024-03-19 07:31:00\n",
      "367070   2024-03-19 12:55:00\n",
      "367071   2024-03-19 13:11:00\n",
      "367072   2024-03-19 17:19:00\n",
      "367073   2024-03-19 17:28:00\n",
      "Name: initiated_time, Length: 367074, dtype: datetime64[ns]\n",
      "Data loaded successfully. Shape: (367074, 40)\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed data\n",
    "df = pd.read_csv('data/preprocessed_tollplaza_data.csv')\n",
    "df['initiated_time'] = pd.to_datetime(df['initiated_time'])\n",
    "df['time_interval'] = pd.to_datetime(df['time_interval'])\n",
    "print(df['initiated_time'])\n",
    "print(\"Data loaded successfully. Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. TRAFFIC PATTERN ANALYSIS\n",
      "--------------------------------------------------\n",
      "Time series data created at 15-minute intervals:\n",
      "       initiated_time  txn_amount  transaction_count  inn_rr_time_sec\n",
      "0 2024-03-19 00:00:00      266256               2469      1882.420008\n",
      "1 2024-03-19 00:15:00      281348               2518       958.048848\n",
      "2 2024-03-19 00:30:00      233571               2091       486.887135\n",
      "3 2024-03-19 00:45:00      237070               2015      1060.671464\n",
      "4 2024-03-19 01:00:00      245842               2097      2214.508822\n",
      "\n",
      "Time series data created at hourly intervals:\n",
      "       initiated_time  txn_amount  transaction_count  inn_rr_time_sec\n",
      "0 2024-03-19 00:00:00     1018245               9093      1123.435170\n",
      "1 2024-03-19 01:00:00      917015               7692      1478.759880\n",
      "2 2024-03-19 02:00:00      790608               6569       913.394885\n",
      "3 2024-03-19 03:00:00      755165               6123       417.210681\n",
      "4 2024-03-19 04:00:00      805013               6792       217.997939\n",
      "\n",
      "Analyzing hourly traffic patterns...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. TRAFFIC PATTERN ANALYSIS\n",
    "print(\"\\n1. TRAFFIC PATTERN ANALYSIS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Aggregate data by time intervals\n",
    "def create_time_series_data(df, interval='15min'):\n",
    "    \"\"\"Create time series data at specified intervals.\"\"\"\n",
    "    ts_data = df.set_index('initiated_time').resample(interval).agg({\n",
    "        'txn_amount': 'sum',\n",
    "        'SlNo.': 'count',  # Count of transactions\n",
    "        'inn_rr_time_sec': 'mean'  # Average processing time\n",
    "    }).reset_index()\n",
    "    \n",
    "    ts_data.rename(columns={'SlNo.': 'transaction_count'}, inplace=True)\n",
    "    return ts_data\n",
    "\n",
    "# Create 15-minute interval data\n",
    "ts_15min = create_time_series_data(df, '15min')\n",
    "print(\"Time series data created at 15-minute intervals:\")\n",
    "print(ts_15min.head())\n",
    "\n",
    "# Create hourly data\n",
    "ts_hourly = create_time_series_data(df, '1H')\n",
    "print(\"\\nTime series data created at hourly intervals:\")\n",
    "print(ts_hourly.head())\n",
    "\n",
    "# Visualize traffic patterns\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(ts_15min['initiated_time'], ts_15min['transaction_count'])\n",
    "plt.title('Traffic Volume Over Time (15-minute intervals)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Transactions')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/traffic_pattern_15min.png')\n",
    "plt.close()\n",
    "\n",
    "# Decompose time series to analyze trend, seasonality, and residuals\n",
    "def analyze_time_series_components(ts_data, column='transaction_count'):\n",
    "    \"\"\"Decompose time series into trend, seasonality, and residual components.\"\"\"\n",
    "    # Set the index to datetime for decomposition\n",
    "    ts = ts_data.set_index('initiated_time')[column]\n",
    "    \n",
    "    # Decompose the time series\n",
    "    decomposition = seasonal_decompose(ts, model='additive', period=12)  # 24 periods for hourly data\n",
    "    \n",
    "    # Plot the decomposition\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(14, 12))\n",
    "    decomposition.observed.plot(ax=ax1)\n",
    "    ax1.set_title('Observed')\n",
    "    decomposition.trend.plot(ax=ax2)\n",
    "    ax2.set_title('Trend')\n",
    "    decomposition.seasonal.plot(ax=ax3)\n",
    "    ax3.set_title('Seasonality')\n",
    "    decomposition.resid.plot(ax=ax4)\n",
    "    ax4.set_title('Residuals')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/time_series_decomposition.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return decomposition\n",
    "\n",
    "# Analyze hourly traffic patterns\n",
    "print(\"\\nAnalyzing hourly traffic patterns...\")\n",
    "decomposition = analyze_time_series_components(ts_hourly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 2. IMPROVED PREDICTIVE MODELS DEVELOPMENT\n",
      "INFO: 2.1 Traffic Volume Prediction Model\n",
      "DEBUG: Target variable stats after enhanced feature engineering: mean=3910.81, std=1215.02\n",
      "DEBUG: Enhanced features shape: (91, 27)\n",
      "DEBUG: Selected features: ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'is_weekend', 'quarter_of_day', 'day_part', 'hour', 'day_of_week', 'lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'rolling_mean_3', 'rolling_std_3', 'rolling_mean_6', 'rolling_max_6', 'rolling_min_6', 'tx_diff_1', 'tx_diff_2', 'tx_per_second', 'avg_amount_per_tx']\n",
      "INFO: Training improved traffic prediction model...\n",
      "INFO: Evaluating XGBoost with time series cross-validation...\n",
      "INFO: XGBoost - Average MAE: 272.28, RMSE: 323.88, R²: 0.0312\n",
      "INFO: Evaluating RandomForest with time series cross-validation...\n",
      "INFO: RandomForest - Average MAE: 223.56, RMSE: 288.83, R²: 0.0826\n",
      "INFO: Evaluating LightGBM with time series cross-validation...\n",
      "INFO: LightGBM - Average MAE: 293.91, RMSE: 370.25, R²: -0.5658\n",
      "INFO: Best model: RandomForest with R²: 0.0826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 300\n",
      "[LightGBM] [Info] Number of data points in the train set: 55, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 3476.400000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 362\n",
      "[LightGBM] [Info] Number of data points in the train set: 67, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 3751.567164\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 423\n",
      "[LightGBM] [Info] Number of data points in the train set: 79, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 3889.303797\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Final Traffic Prediction metrics - MAE: 223.56, RMSE: 288.83, R²: 0.0826\n",
      "INFO: 2.2 Improved Vehicle Class Distribution Prediction\n",
      "DEBUG: Vehicle class distribution (percentage) shape: (24, 14)\n",
      "INFO: Training improved vehicle class prediction model...\n",
      "INFO: Vehicle Class Prediction - Average MAE: 345.82, RMSE: 1089.15\n",
      "DEBUG: Predicted vehicle class distribution for next hour:\n",
      "vehicle_class_code        VC10        VC11        VC12        VC13       VC14      VC15  VC16        VC20         VC4         VC5  VC6         VC7        VC8        VC9\n",
      "0                   643.255756  345.888879  617.227506  383.952339  94.918687  2.343327   0.0  593.235591  4354.61447  491.061954  0.0  463.054702  24.959446  27.226877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For time series analysis and models\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# For machine learning pipelines and evaluation\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# -------------------------------\n",
    "# 2. IMPROVED PREDICTIVE MODELS DEVELOPMENT\n",
    "# -------------------------------\n",
    "logging.info(\"2. IMPROVED PREDICTIVE MODELS DEVELOPMENT\")\n",
    "\n",
    "# 2.1 Traffic Volume Prediction Model\n",
    "logging.info(\"2.1 Traffic Volume Prediction Model\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2.1.1 Enhanced Feature preparation\n",
    "# -------------------------------\n",
    "def prepare_features_for_prediction(df):\n",
    "    \"\"\"\n",
    "    Prepare features for traffic prediction models with enhanced feature engineering.\n",
    "    Adds time-based features, cyclical encodings, and multiple lag features and rolling statistics.\n",
    "    \"\"\"\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Time-based features\n",
    "    features['hour'] = features['initiated_time'].dt.hour\n",
    "    features['day_of_week'] = features['initiated_time'].dt.dayofweek\n",
    "    features['is_weekend'] = features['day_of_week'].isin([5, 6]).astype(int)\n",
    "    features['quarter_of_day'] = features['hour'] // 6\n",
    "    features['day_part'] = pd.cut(features['hour'], \n",
    "                                bins=[0, 6, 12, 18, 24], \n",
    "                                labels=['night', 'morning', 'afternoon', 'evening'])\n",
    "    features['day_part'] = features['day_part'].astype('category').cat.codes\n",
    "    \n",
    "    # Create cyclical time features\n",
    "    features['hour_sin'] = np.sin(2 * np.pi * features['hour'] / 24)\n",
    "    features['hour_cos'] = np.cos(2 * np.pi * features['hour'] / 24)\n",
    "    features['day_sin'] = np.sin(2 * np.pi * features['day_of_week'] / 7)\n",
    "    features['day_cos'] = np.cos(2 * np.pi * features['day_of_week'] / 7)\n",
    "    \n",
    "    # Add lag features with more historical context\n",
    "    for lag in range(1, 6):  # Use 5 lag periods\n",
    "        features[f'lag_{lag}'] = features['transaction_count'].shift(lag)\n",
    "    \n",
    "    # Add rolling statistics\n",
    "    features['rolling_mean_3'] = features['transaction_count'].rolling(window=3).mean()\n",
    "    features['rolling_std_3'] = features['transaction_count'].rolling(window=3).std()\n",
    "    features['rolling_mean_6'] = features['transaction_count'].rolling(window=6).mean()\n",
    "    features['rolling_max_6'] = features['transaction_count'].rolling(window=6).max()\n",
    "    features['rolling_min_6'] = features['transaction_count'].rolling(window=6).min()\n",
    "    \n",
    "    # Calculate transaction differences\n",
    "    features['tx_diff_1'] = features['transaction_count'].diff(1)\n",
    "    features['tx_diff_2'] = features['transaction_count'].diff(2)\n",
    "    \n",
    "    # Add transaction rate features\n",
    "    if 'inn_rr_time_sec' in features.columns:\n",
    "        features['tx_per_second'] = features['transaction_count'] / features['inn_rr_time_sec']\n",
    "        features['tx_per_second'].fillna(features['tx_per_second'].mean(), inplace=True)\n",
    "    \n",
    "    # Add average transaction amount per transaction\n",
    "    if 'txn_amount' in features.columns:\n",
    "        features['avg_amount_per_tx'] = features['txn_amount'] / features['transaction_count']\n",
    "        features['avg_amount_per_tx'].fillna(features['avg_amount_per_tx'].mean(), inplace=True)\n",
    "    \n",
    "    # Drop NaN values created by lag and rolling features\n",
    "    features.dropna(inplace=True)\n",
    "    \n",
    "    # Debug: output basic stats of target variable\n",
    "    logging.debug(\"Target variable stats after enhanced feature engineering: mean=%.2f, std=%.2f\", \n",
    "                  features['transaction_count'].mean(), features['transaction_count'].std())\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Assume ts_15min is your 15-minute aggregated DataFrame that already includes 'transaction_count'\n",
    "ts_features = prepare_features_for_prediction(ts_15min)\n",
    "logging.debug(\"Enhanced features shape: %s\", ts_features.shape)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 2.1.2 Improved data splitting and feature selection\n",
    "# -------------------------------\n",
    "def select_features_and_split(features_df):\n",
    "\n",
    "    # Select features with different types for separate preprocessing\n",
    "    time_cyclical_features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
    "    categorical_features = ['is_weekend', 'quarter_of_day', 'day_part']\n",
    "    numerical_features = ['hour', 'day_of_week']\n",
    "    \n",
    "    # Get lag and rolling features dynamically\n",
    "    lag_features = [col for col in features_df.columns if col.startswith('lag_')]\n",
    "    rolling_features = [col for col in features_df.columns if col.startswith('rolling_')]\n",
    "    diff_features = [col for col in features_df.columns if col.startswith('tx_diff')]\n",
    "    \n",
    "    # Additional features if available\n",
    "    additional_features = []\n",
    "    if 'tx_per_second' in features_df.columns:\n",
    "        additional_features.append('tx_per_second')\n",
    "    if 'avg_amount_per_tx' in features_df.columns:\n",
    "        additional_features.append('avg_amount_per_tx')\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = time_cyclical_features + categorical_features + numerical_features + \\\n",
    "                  lag_features + rolling_features + diff_features + additional_features\n",
    "    \n",
    "    X = features_df[all_features]\n",
    "    y = features_df['transaction_count']\n",
    "    \n",
    "    # Return features categorized for proper preprocessing\n",
    "    feature_groups = {\n",
    "        'time_cyclical': time_cyclical_features,\n",
    "        'categorical': categorical_features,\n",
    "        'numerical': numerical_features,\n",
    "        'lag': lag_features,\n",
    "        'rolling': rolling_features,\n",
    "        'diff': diff_features,\n",
    "        'additional': additional_features\n",
    "    }\n",
    "    \n",
    "    return X, y, feature_groups\n",
    "\n",
    "X, y, feature_groups = select_features_and_split(ts_features)\n",
    "logging.debug(\"Selected features: %s\", X.columns.tolist())\n",
    "\n",
    "# -------------------------------\n",
    "# 2.1.3 Improved Model Training & Evaluation\n",
    "# -------------------------------\n",
    "def create_preprocessor(feature_groups):\n",
    "    \"\"\"\n",
    "    Create a column transformer to appropriately preprocess different feature types\n",
    "    \"\"\"\n",
    "    transformers = [\n",
    "        ('time_cyclical', 'passthrough', feature_groups['time_cyclical']),\n",
    "        ('categorical', 'passthrough', feature_groups['categorical']),\n",
    "        ('numerical', StandardScaler(), feature_groups['numerical']),\n",
    "        ('lag', RobustScaler(), feature_groups['lag']),\n",
    "        ('rolling', RobustScaler(), feature_groups['rolling']),\n",
    "        ('diff', RobustScaler(), feature_groups['diff'])\n",
    "    ]\n",
    "    \n",
    "    # Add additional features if they exist\n",
    "    if feature_groups['additional']:\n",
    "        transformers.append(('additional', RobustScaler(), feature_groups['additional']))\n",
    "    \n",
    "    preprocessor = ColumnTransformer(transformers, remainder='drop')\n",
    "    return preprocessor\n",
    "\n",
    "def train_traffic_prediction_model(X, y, feature_groups):\n",
    "\n",
    "    # Create preprocessor\n",
    "    preprocessor = create_preprocessor(feature_groups)\n",
    "    \n",
    "    # Define time series split for proper evaluation\n",
    "    tscv = TimeSeriesSplit(n_splits=3, test_size=12)\n",
    "    \n",
    "    # Define candidate models\n",
    "    models = {\n",
    "        'XGBoost': XGBRegressor(\n",
    "            n_estimators=200, \n",
    "            learning_rate=0.05, \n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            gamma=1,\n",
    "            reg_lambda=2,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'RandomForest': RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=4,\n",
    "            random_state=42\n",
    "        ),\n",
    "        'LightGBM': LGBMRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_lambda=2,\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = float('-inf')\n",
    "    best_metrics = None\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for name, model_instance in models.items():\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', model_instance)\n",
    "        ])\n",
    "        \n",
    "        # Use cross-validation to evaluate model\n",
    "        cv_scores = []\n",
    "        mae_scores = []\n",
    "        rmse_scores = []\n",
    "        r2_scores = []\n",
    "        \n",
    "        logging.info(f\"Evaluating {name} with time series cross-validation...\")\n",
    "        \n",
    "        for train_idx, test_idx in tscv.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            mae_scores.append(mae)\n",
    "            rmse_scores.append(rmse)\n",
    "            r2_scores.append(r2)\n",
    "        \n",
    "        # Average scores across folds\n",
    "        avg_mae = np.mean(mae_scores)\n",
    "        avg_rmse = np.mean(rmse_scores)\n",
    "        avg_r2 = np.mean(r2_scores)\n",
    "        \n",
    "        logging.info(f\"{name} - Average MAE: {avg_mae:.2f}, RMSE: {avg_rmse:.2f}, R²: {avg_r2:.4f}\")\n",
    "        \n",
    "        # Update best model if this one is better\n",
    "        if avg_r2 > best_score:\n",
    "            best_score = avg_r2\n",
    "            best_model = pipeline\n",
    "            best_metrics = {\n",
    "                'name': name,\n",
    "                'mae': avg_mae,\n",
    "                'rmse': avg_rmse,\n",
    "                'r2': avg_r2\n",
    "            }\n",
    "    \n",
    "    # Train the best model on all data\n",
    "    logging.info(f\"Best model: {best_metrics['name']} with R²: {best_metrics['r2']:.4f}\")\n",
    "    best_model.fit(X, y)\n",
    "    \n",
    "    # Get feature importance if the model supports it\n",
    "    if hasattr(best_model['regressor'], 'feature_importances_'):\n",
    "        feature_names = X.columns\n",
    "        importances = best_model['regressor'].feature_importances_\n",
    "        sorted_idx = np.argsort(importances)[::-1]\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.barh(range(len(sorted_idx)), importances[sorted_idx])\n",
    "        plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "        plt.title('Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('images/feature_importance.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Plot actual vs predicted for the last fold\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(y_test.values, label='Actual', marker='o')\n",
    "    plt.plot(y_pred, label='Predicted', marker='x')\n",
    "    plt.title('Traffic Volume: Actual vs Predicted')\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Transaction Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/traffic_prediction_results.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return best_model, best_metrics\n",
    "\n",
    "logging.info(\"Training improved traffic prediction model...\")\n",
    "traffic_model, metrics = train_traffic_prediction_model(X, y, feature_groups)\n",
    "logging.info(f\"Final Traffic Prediction metrics - MAE: {metrics['mae']:.2f}, RMSE: {metrics['rmse']:.2f}, R²: {metrics['r2']:.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2.2 Vehicle Class Distribution Prediction\n",
    "# -------------------------------\n",
    "logging.info(\"2.2 Improved Vehicle Class Distribution Prediction\")\n",
    "\n",
    "def create_vehicle_class_timeseries(df, interval='1H'):\n",
    "    \"\"\"\n",
    "    Create time series data of vehicle class distribution.\n",
    "    Returns absolute counts (vc_ts) and percentage distribution (vc_ts_pct).\n",
    "    \"\"\"\n",
    "    vc_ts = df.set_index('initiated_time').groupby([pd.Grouper(freq=interval), 'vehicle_class_code']).size().unstack(fill_value=0)\n",
    "    vc_ts_pct = vc_ts.div(vc_ts.sum(axis=1), axis=0) * 100\n",
    "    return vc_ts, vc_ts_pct\n",
    "\n",
    "# Create vehicle class time series\n",
    "vc_hourly, vc_hourly_pct = create_vehicle_class_timeseries(df, '1H')\n",
    "logging.debug(\"Vehicle class distribution (percentage) shape: %s\", vc_hourly_pct.shape)\n",
    "\n",
    "# Plot vehicle class distribution\n",
    "plt.figure(figsize=(14, 8))\n",
    "vc_hourly_pct.plot(kind='area', stacked=True, colormap='viridis')\n",
    "plt.title('Vehicle Class Distribution Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Percentage of Vehicles')\n",
    "plt.legend(title='Vehicle Class', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/vehicle_class_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# -------------------------------\n",
    "# 2.2.1 Vehicle Class Prediction\n",
    "# -------------------------------\n",
    "def train_vehicle_class_prediction_model(vc_hourly):\n",
    "\n",
    "    vc_features = vc_hourly.reset_index()\n",
    "    \n",
    "    # Enhanced time features\n",
    "    vc_features['hour'] = vc_features['initiated_time'].dt.hour\n",
    "    vc_features['day_of_week'] = vc_features['initiated_time'].dt.dayofweek\n",
    "    vc_features['is_weekend'] = vc_features['day_of_week'].isin([5, 6]).astype(int)\n",
    "    vc_features['day_part'] = pd.cut(vc_features['hour'], \n",
    "                                      bins=[0, 6, 12, 18, 24], \n",
    "                                      labels=['night', 'morning', 'afternoon', 'evening'])\n",
    "    vc_features['day_part'] = vc_features['day_part'].astype('category').cat.codes\n",
    "    \n",
    "    # Cyclical features\n",
    "    vc_features['hour_sin'] = np.sin(2 * np.pi * vc_features['hour'] / 24)\n",
    "    vc_features['hour_cos'] = np.cos(2 * np.pi * vc_features['hour'] / 24)\n",
    "    vc_features['day_sin'] = np.sin(2 * np.pi * vc_features['day_of_week'] / 7)\n",
    "    vc_features['day_cos'] = np.cos(2 * np.pi * vc_features['day_of_week'] / 7)\n",
    "    \n",
    "    # Feature selection\n",
    "    X_cols = ['hour', 'day_of_week', 'is_weekend', 'day_part',\n",
    "              'hour_sin', 'hour_cos', 'day_sin', 'day_cos']\n",
    "    X = vc_features[X_cols]\n",
    "    y = vc_hourly.values  # each column corresponds to a vehicle class\n",
    "    \n",
    "    # Create column transformer for different feature types\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('cyclical', 'passthrough', ['hour_sin', 'hour_cos', 'day_sin', 'day_cos']),\n",
    "        ('numerical', StandardScaler(), ['hour', 'day_of_week']),\n",
    "        ('categorical', 'passthrough', ['is_weekend', 'day_part'])\n",
    "    ])\n",
    "    \n",
    "    # Create time series split for proper validation\n",
    "    tscv = TimeSeriesSplit(n_splits=3, test_size=6)\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    model = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(n_estimators=200, \n",
    "                                           max_depth=8, \n",
    "                                           min_samples_split=5, \n",
    "                                           random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Use cross-validation to evaluate model\n",
    "    mae_scores = []\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        \n",
    "        mae_scores.append(mae)\n",
    "        rmse_scores.append(rmse)\n",
    "    \n",
    "    # Average scores across folds\n",
    "    avg_mae = np.mean(mae_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    \n",
    "    logging.info(f\"Vehicle Class Prediction - Average MAE: {avg_mae:.2f}, RMSE: {avg_rmse:.2f}\")\n",
    "    \n",
    "    # Train final model on all data\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Get a test prediction to evaluate\n",
    "    last_date = vc_features['initiated_time'].max()\n",
    "    next_hour = last_date + pd.Timedelta(hours=1)\n",
    "    \n",
    "    # Create feature vector for next hour prediction\n",
    "    next_x = pd.DataFrame({\n",
    "        'hour': [next_hour.hour],\n",
    "        'day_of_week': [next_hour.dayofweek],\n",
    "        'is_weekend': [1 if next_hour.dayofweek >= 5 else 0],\n",
    "        'day_part': [next_hour.hour // 6],\n",
    "        'hour_sin': [np.sin(2 * np.pi * next_hour.hour / 24)],\n",
    "        'hour_cos': [np.cos(2 * np.pi * next_hour.hour / 24)],\n",
    "        'day_sin': [np.sin(2 * np.pi * next_hour.dayofweek / 7)],\n",
    "        'day_cos': [np.cos(2 * np.pi * next_hour.dayofweek / 7)]\n",
    "    })\n",
    "    \n",
    "    # Predict next hour's distribution\n",
    "    next_distribution = model.predict(next_x)[0]  # Get first element to make it 2D\n",
    "    predicted_distribution = pd.DataFrame([next_distribution], columns=vc_hourly.columns)\n",
    "    \n",
    "    logging.debug(\"Predicted vehicle class distribution for next hour:\\n%s\", \n",
    "                  predicted_distribution.to_string())\n",
    "    \n",
    "    # Visualize predictions vs actuals for last test fold\n",
    "    last_train_idx, last_test_idx = list(tscv.split(X))[-1]\n",
    "    X_train, X_test = X.iloc[last_train_idx], X.iloc[last_test_idx]\n",
    "    y_train, y_test = y[last_train_idx], y[last_test_idx]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Convert to DataFrames for easier plotting\n",
    "    y_test_df = pd.DataFrame(y_test, columns=vc_hourly.columns)\n",
    "    y_pred_df = pd.DataFrame(y_pred, columns=vc_hourly.columns)\n",
    "    \n",
    "    # Select top 5 vehicle classes by volume for visualization\n",
    "    top_classes = vc_hourly.sum().sort_values(ascending=False).head(5).index.tolist()\n",
    "    top_classes2 = vc_hourly.sum().sort_values(ascending=False).index.tolist()\n",
    "    print(\"siochsiohchsioc\",top_classes2)\n",
    "    # Plot actual vs predicted for top classes\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for i, vc in enumerate(top_classes):\n",
    "        plt.subplot(len(top_classes), 1, i+1)\n",
    "        plt.plot(y_test_df.index, y_test_df[vc], 'b-', label=f'Actual {vc}')\n",
    "        plt.plot(y_test_df.index, y_pred_df[vc], 'r--', label=f'Predicted {vc}')\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend()\n",
    "        if i == 0:\n",
    "            plt.title('Top Vehicle Classes: Actual vs. Predicted')\n",
    "        if i == len(top_classes) - 1:\n",
    "            plt.xlabel('Time Index')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/vehicle_class_prediction_results.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return model, avg_mae, avg_rmse\n",
    "\n",
    "logging.info(\"Training improved vehicle class prediction model...\")\n",
    "if not vc_hourly.empty:\n",
    "    vc_model, vc_mae, vc_rmse = train_vehicle_class_prediction_model(vc_hourly)\n",
    "else:\n",
    "    logging.warning(\"No vehicle class data available for modeling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. ANOMALY DETECTION SYSTEM\n",
      "--------------------------------------------------\n",
      "\n",
      "3.1 Traffic Pattern Anomaly Detection\n",
      "\n",
      "Building traffic anomaly detection models...\n",
      "\n",
      "Training Isolation Forest model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: locator: <matplotlib.ticker.AutoLocator object at 0x0000019F850A1190>\n",
      "DEBUG: colorbar update normal <matplotlib.colors.Normalize object at 0x0000019F843844A0> <matplotlib.colors.Normalize object at 0x0000019F843844A0>\n",
      "DEBUG: locator: <matplotlib.ticker.AutoLocator object at 0x0000019F923C3110>\n",
      "DEBUG: colorbar update normal <matplotlib.colors.Normalize object at 0x0000019F843844A0> <matplotlib.colors.Normalize object at 0x0000019F843844A0>\n",
      "DEBUG: locator: <matplotlib.ticker.AutoLocator object at 0x0000019F923C3110>\n",
      "DEBUG: locator: <matplotlib.ticker.AutoLocator object at 0x0000019F856E0290>\n",
      "DEBUG: locator: <matplotlib.ticker.AutoLocator object at 0x0000019F8DDD3110>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DBSCAN model...\n",
      "Isolation Forest: Detected 5 anomalies out of 96 intervals\n",
      "DBSCAN: Detected 0 anomalies out of 96 intervals\n",
      "Ensemble: Detected 5 anomalies out of 96 intervals\n",
      "\n",
      "Top 10 detected traffic anomalies:\n",
      "        initiated_time  transaction_count\n",
      "73 2024-03-19 18:15:00               5598\n",
      "61 2024-03-19 15:15:00               5582\n",
      "87 2024-03-19 21:45:00               3514\n",
      "1  2024-03-19 00:15:00               2518\n",
      "0  2024-03-19 00:00:00               2469\n",
      "\n",
      "3.2 Toll Skipping Detection\n",
      "\n",
      "Detecting potential toll skipping patterns...\n",
      "Available columns in dataframe:\n",
      "['SlNo.', 'merchant_name', 'direction', 'lane', 'tag_id', 'vehicle_regn_number', 'txn_amount', 'initiated_time', 'inn_rr_time_sec', 'vehicle_class_code', 'vehicle_comvehicle', 'geocode', 'merchant_sub_type', 'city', 'state', 'hour', 'day_of_week', 'txn_amount_scaled', 'vehicle_class_code_enc', 'merchant_name_enc', 'minute', 'time_of_day', 'latitude', 'longitude', 'merchant_name_encoded', 'direction_encoded', 'lane_encoded', 'vehicle_class_code_encoded', 'merchant_sub_type_encoded', 'city_encoded', 'state_encoded', 'hour_sin', 'hour_cos', 'minute_sin', 'minute_cos', 'day_sin', 'day_cos', 'time_interval', 'traffic_count', 'is_frequent_traveler']\n",
      "Using 'vehicle_regn_number' as vehicle identifier\n",
      "Grouping by vehicle_regn_number...\n",
      "Found 74132 vehicles with multiple trips\n",
      "\n",
      "Performing K-Means clustering...\n",
      "Optimal number of clusters determined: 7\n",
      "Performing DBSCAN clustering...\n",
      "\n",
      "K-Means Cluster statistics:\n",
      "                total_trips  unique_plazas  trips_per_hour  \\\n",
      "kmeans_cluster                                               \n",
      "0                  2.000000       1.000000        0.376511   \n",
      "1                  2.016343       2.016343        0.369496   \n",
      "2                  2.055219       2.013521        1.998256   \n",
      "3                  2.013006       1.000000        1.722762   \n",
      "4                  3.583250       1.027716        0.367002   \n",
      "5                  3.339095       2.138288        0.490291   \n",
      "6                  2.178269       1.326936        0.564254   \n",
      "\n",
      "                avg_amount_per_trip  plaza_to_trip_ratio  vehicle_count  \n",
      "kmeans_cluster                                                           \n",
      "0                         53.472179             0.500000          30211  \n",
      "1                         70.823339             1.000000           7404  \n",
      "2                         60.822405             0.986613          10576  \n",
      "3                         58.992747             0.497832           8227  \n",
      "4                         84.353357             0.299361           4979  \n",
      "5                         53.036352             0.651921           9661  \n",
      "6                        310.340924             0.621346           3074  \n",
      "\n",
      "Potential toll skipping K-Means cluster identified: Cluster 4\n",
      "This cluster has 4979 vehicles\n",
      "\n",
      "DBSCAN identified 184 potential outlier vehicles\n",
      "\n",
      "Combined unique suspect vehicles from both methods: 5120\n",
      "High confidence suspects (detected by both methods): 43\n",
      "\n",
      "Sample of potential toll skipping vehicles:\n",
      "                             first_seen           last_seen  total_trips  \\\n",
      "vehicle_regn_number                                                        \n",
      "AEERX               2024-03-19 00:38:00 2024-03-19 22:59:00            6   \n",
      "CPWPT               2024-03-19 01:17:00 2024-03-19 23:09:00            6   \n",
      "CVCFM               2024-03-19 11:45:00 2024-03-19 19:47:00            8   \n",
      "DBKRX               2024-03-19 01:04:00 2024-03-19 17:29:00           10   \n",
      "EVRBO               2024-03-19 07:19:00 2024-03-19 09:04:00            4   \n",
      "\n",
      "                     unique_plazas  total_amount  time_span_hours  \\\n",
      "vehicle_regn_number                                                 \n",
      "AEERX                            2          2185        22.350000   \n",
      "CPWPT                            2          1195        21.866667   \n",
      "CVCFM                            1          2140         8.033333   \n",
      "DBKRX                            2           830        16.416667   \n",
      "EVRBO                            1           340         1.750000   \n",
      "\n",
      "                     trips_per_hour  avg_amount_per_trip  plaza_to_trip_ratio  \\\n",
      "vehicle_regn_number                                                             \n",
      "AEERX                      0.268456           364.166667             0.333333   \n",
      "CPWPT                      0.274390           199.166667             0.333333   \n",
      "CVCFM                      0.995851           267.500000             0.125000   \n",
      "DBKRX                      0.609137            83.000000             0.200000   \n",
      "EVRBO                      2.285714            85.000000             0.250000   \n",
      "\n",
      "                     kmeans_cluster  dbscan_cluster  combined_score  \n",
      "vehicle_regn_number                                                  \n",
      "AEERX                             4              -1               2  \n",
      "CPWPT                             4              -1               2  \n",
      "CVCFM                             4              -1               2  \n",
      "DBKRX                             4              -1               2  \n",
      "EVRBO                             4              -1               2  \n",
      "\n",
      "3.3 Building supervised vehicle behavior classifier\n",
      "Creating synthetic labeled dataset for demonstration...\n",
      "\n",
      "Vehicle behavior classifier metrics:\n",
      "Accuracy: 0.7308\n",
      "Precision: 0.6923\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.7200\n",
      "\n",
      "Feature importance for detecting suspicious vehicles:\n",
      "               Feature  Importance\n",
      "4  plaza_to_trip_ratio    0.495509\n",
      "2       trips_per_hour    0.175111\n",
      "3  avg_amount_per_trip    0.141509\n",
      "0          total_trips    0.108701\n",
      "1        unique_plazas    0.079170\n",
      "\n",
      "3.4 Enhanced Traffic Pattern Analysis\n",
      "\n",
      "Analyzing traffic patterns with anomaly information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO: Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most anomalous hours of the day:\n",
      "Hour 0: 50.00% anomalies\n",
      "Hour 21: 25.00% anomalies\n",
      "Hour 18: 25.00% anomalies\n",
      "\n",
      "Most anomalous days of the week:\n",
      "Tuesday: 5.21% anomalies\n",
      "\n",
      "4. SAVING MODELS AND RESULTS\n",
      "--------------------------------------------------\n",
      "Traffic prediction model saved as 'traffic_prediction_model.pkl'\n",
      "Traffic anomaly detection models saved as 'traffic_anomaly_models.pkl'\n",
      "Vehicle class prediction model saved as 'vehicle_class_prediction_model.pkl'\n",
      "Toll skipping detection models saved as 'toll_skipping_models.pkl'\n",
      "Vehicle behavior classifier saved as 'vehicle_behavior_classifier.pkl'\n",
      "Detected anomalies saved as 'detected_anomalies.csv'\n",
      "Potential toll skipping vehicles saved as 'potential_toll_skipping_vehicles.csv'\n",
      "Traffic pattern analysis results saved as CSV files\n",
      "\n",
      "Phase 2: Enhanced Analytics Models complete!\n"
     ]
    }
   ],
   "source": [
    "# 3. ANOMALY DETECTION SYSTEM\n",
    "print(\"\\n3. ANOMALY DETECTION SYSTEM\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# 3.1 Traffic Pattern Anomaly Detection\n",
    "print(\"\\n3.1 Traffic Pattern Anomaly Detection\")\n",
    "\n",
    "def build_traffic_anomaly_detector(ts_data):\n",
    "    \"\"\"Build an anomaly detection model for traffic patterns using multiple methods.\"\"\"\n",
    "    # Prepare features\n",
    "    features = ts_data.copy()\n",
    "    features['hour'] = features['initiated_time'].dt.hour\n",
    "    features['day_of_week'] = features['initiated_time'].dt.dayofweek\n",
    "    features['is_weekend'] = features['day_of_week'].isin([5, 6]).astype(int)\n",
    "    features['month'] = features['initiated_time'].dt.month\n",
    "    features['day'] = features['initiated_time'].dt.day\n",
    "    \n",
    "    # Features for anomaly detection\n",
    "    X = features[['transaction_count', 'hour', 'day_of_week', 'is_weekend', 'month', 'day']]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Initialize dictionary to store models and results\n",
    "    models = {}\n",
    "    \n",
    "    # 1. Isolation Forest model\n",
    "    print(\"\\nTraining Isolation Forest model...\")\n",
    "    if_model = IsolationForest(\n",
    "        contamination=0.05,  # Expected proportion of anomalies\n",
    "        n_estimators=200,    # Increased number of trees\n",
    "        max_samples='auto',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    if_model.fit(X_scaled)\n",
    "    \n",
    "    # Predict anomalies\n",
    "    features['if_anomaly'] = if_model.predict(X_scaled)\n",
    "    features['if_anomaly_score'] = if_model.score_samples(X_scaled)\n",
    "    features['if_is_anomaly'] = features['if_anomaly'].apply(lambda x: 1 if x == -1 else 0)\n",
    "    \n",
    "    # Store model in dictionary\n",
    "    models['isolation_forest'] = (if_model, features[features['if_is_anomaly'] == 1])\n",
    "    \n",
    "    # 2. DBSCAN clustering for anomaly detection\n",
    "    print(\"Training DBSCAN model...\")\n",
    "    dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "    features['dbscan_cluster'] = dbscan.fit_predict(X_scaled)\n",
    "    \n",
    "    # Mark outliers (cluster -1) as anomalies\n",
    "    features['dbscan_is_anomaly'] = (features['dbscan_cluster'] == -1).astype(int)\n",
    "    \n",
    "    # Store model in dictionary\n",
    "    models['dbscan'] = (dbscan, features[features['dbscan_is_anomaly'] == 1])\n",
    "    \n",
    "    # Create ensemble anomaly detection (combine results from both methods)\n",
    "    features['ensemble_score'] = features['if_is_anomaly'] + features['dbscan_is_anomaly']\n",
    "    features['ensemble_is_anomaly'] = (features['ensemble_score'] > 0).astype(int)\n",
    "    \n",
    "    # Count anomalies for each method\n",
    "    if_anomaly_count = features['if_is_anomaly'].sum()\n",
    "    dbscan_anomaly_count = features['dbscan_is_anomaly'].sum()\n",
    "    ensemble_anomaly_count = features['ensemble_is_anomaly'].sum()\n",
    "    \n",
    "    print(f\"Isolation Forest: Detected {if_anomaly_count} anomalies out of {len(features)} intervals\")\n",
    "    print(f\"DBSCAN: Detected {dbscan_anomaly_count} anomalies out of {len(features)} intervals\")\n",
    "    print(f\"Ensemble: Detected {ensemble_anomaly_count} anomalies out of {len(features)} intervals\")\n",
    "    \n",
    "    # Visualize anomalies for each method\n",
    "    plt.figure(figsize=(18, 12))\n",
    "    \n",
    "    # Isolation Forest\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(features['initiated_time'], features['transaction_count'], \n",
    "                c=features['if_is_anomaly'], cmap='coolwarm', alpha=0.6)\n",
    "    plt.title('Isolation Forest Anomaly Detection')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Transaction Count')\n",
    "    plt.colorbar(label='Anomaly (1) / Normal (0)')\n",
    "    \n",
    "    # DBSCAN\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter(features['initiated_time'], features['transaction_count'], \n",
    "                c=features['dbscan_is_anomaly'], cmap='coolwarm', alpha=0.6)\n",
    "    plt.title('DBSCAN Anomaly Detection')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Transaction Count')\n",
    "    plt.colorbar(label='Anomaly (1) / Normal (0)')\n",
    "    \n",
    "    # Ensemble\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.scatter(features['initiated_time'], features['transaction_count'], \n",
    "                c=features['ensemble_is_anomaly'], cmap='coolwarm', alpha=0.6)\n",
    "    plt.title('Ensemble Anomaly Detection')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Transaction Count')\n",
    "    plt.colorbar(label='Anomaly (1) / Normal (0)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/traffic_anomalies_comparison.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Return models and anomalies\n",
    "    ensemble_anomalies = features[features['ensemble_is_anomaly'] == 1]\n",
    "    return models, scaler, ensemble_anomalies, features\n",
    "\n",
    "# Build traffic anomaly detector\n",
    "print(\"\\nBuilding traffic anomaly detection models...\")\n",
    "anomaly_models, anomaly_scaler, anomalies, features_with_anomalies = build_traffic_anomaly_detector(ts_15min)\n",
    "\n",
    "# Show the detected anomalies\n",
    "print(\"\\nTop 10 detected traffic anomalies:\")\n",
    "print(anomalies[['initiated_time', 'transaction_count']].sort_values('transaction_count', ascending=False).head(10))\n",
    "\n",
    "# 3.2 Toll Skipping Detection\n",
    "print(\"\\n3.2 Toll Skipping Detection\")\n",
    "\n",
    "def detect_potential_toll_skipping(df):\n",
    "    \"\"\"Detect potential toll skipping patterns.\"\"\"\n",
    "    # Print columns for debugging\n",
    "    print(\"Available columns in dataframe:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Check if the vehicle registration column exists\n",
    "    vehicle_col = 'vehicle_regn_number'\n",
    "    \n",
    "    if vehicle_col not in df.columns:\n",
    "        # Try to find alternatives\n",
    "        possible_columns = [col for col in df.columns if any(term in col.lower() for term in \n",
    "                           ['vehicle', 'regn', 'registration', 'reg', 'tag', 'transponder', 'id'])]\n",
    "        \n",
    "        if possible_columns:\n",
    "            vehicle_col = possible_columns[0]\n",
    "            print(f\"Using alternative column: '{vehicle_col}'\")\n",
    "        else:\n",
    "            print(\"No suitable vehicle identifier found. Creating synthetic ID.\")\n",
    "            df['synthetic_vehicle_id'] = range(1, len(df) + 1)\n",
    "            vehicle_col = 'synthetic_vehicle_id'\n",
    "    \n",
    "    print(f\"Using '{vehicle_col}' as vehicle identifier\")\n",
    "    \n",
    "    # Group by vehicle identifier\n",
    "    print(f\"Grouping by {vehicle_col}...\")\n",
    "    vehicle_trips = df.groupby(vehicle_col).agg({\n",
    "        'initiated_time': ['min', 'max', 'count'],\n",
    "        'merchant_name': 'nunique',\n",
    "        'txn_amount': 'sum'\n",
    "    })\n",
    "    \n",
    "    vehicle_trips.columns = ['first_seen', 'last_seen', 'total_trips', 'unique_plazas', 'total_amount']\n",
    "    \n",
    "    # Calculate time difference between first and last trip\n",
    "    vehicle_trips['time_span_hours'] = (vehicle_trips['last_seen'] - vehicle_trips['first_seen']).dt.total_seconds() / 3600\n",
    "    \n",
    "    # Calculate average transactions per hour active\n",
    "    vehicle_trips['trips_per_hour'] = vehicle_trips['total_trips'] / vehicle_trips['time_span_hours'].clip(lower=1)\n",
    "    \n",
    "    # Calculate average amount per trip\n",
    "    vehicle_trips['avg_amount_per_trip'] = vehicle_trips['total_amount'] / vehicle_trips['total_trips']\n",
    "    \n",
    "    # Calculate ratio of unique plazas to total trips\n",
    "    vehicle_trips['plaza_to_trip_ratio'] = vehicle_trips['unique_plazas'] / vehicle_trips['total_trips']\n",
    "    \n",
    "    # Filter for vehicles with multiple trips\n",
    "    multi_trip_vehicles = vehicle_trips[vehicle_trips['total_trips'] > 1].copy()\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    if len(multi_trip_vehicles) > 0:\n",
    "        print(f\"Found {len(multi_trip_vehicles)} vehicles with multiple trips\")\n",
    "        \n",
    "        # Features for clustering\n",
    "        features = multi_trip_vehicles[['total_trips', 'unique_plazas', 'trips_per_hour', \n",
    "                                       'avg_amount_per_trip', 'plaza_to_trip_ratio']]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        \n",
    "        # Try multiple clustering algorithms\n",
    "        \n",
    "        # 1. K-Means clustering\n",
    "        print(\"\\nPerforming K-Means clustering...\")\n",
    "        # Determine optimal number of clusters\n",
    "        inertia = []\n",
    "        k_range = range(1, min(11, len(features_scaled)))\n",
    "        for k in k_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            kmeans.fit(features_scaled)\n",
    "            inertia.append(kmeans.inertia_)\n",
    "        \n",
    "        # Plot elbow curve\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(k_range, inertia, 'o-')\n",
    "        plt.xlabel('Number of Clusters')\n",
    "        plt.ylabel('Inertia')\n",
    "        plt.title('Elbow Method for Optimal k')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('images/kmeans_elbow_curve.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Choose optimal k (simplified method)\n",
    "        optimal_k = 3\n",
    "        if len(inertia) > 2:\n",
    "            for i in range(1, len(inertia)-1):\n",
    "                if (inertia[i-1] - inertia[i]) > 3 * (inertia[i] - inertia[i+1]):\n",
    "                    optimal_k = i+1\n",
    "                    break\n",
    "        \n",
    "        print(f\"Optimal number of clusters determined: {optimal_k}\")\n",
    "        \n",
    "        # Perform KMeans clustering\n",
    "        kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "        multi_trip_vehicles['kmeans_cluster'] = kmeans.fit_predict(features_scaled)\n",
    "        \n",
    "        # Store model\n",
    "        models['kmeans'] = kmeans\n",
    "        \n",
    "        # 2. DBSCAN clustering\n",
    "        print(\"Performing DBSCAN clustering...\")\n",
    "        dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "        multi_trip_vehicles['dbscan_cluster'] = dbscan.fit_predict(features_scaled)\n",
    "        \n",
    "        # Store model\n",
    "        models['dbscan'] = dbscan\n",
    "        \n",
    "        # Analyze KMeans clusters - FIXED: use count() instead of vehicle_col\n",
    "        kmeans_cluster_stats = multi_trip_vehicles.groupby('kmeans_cluster').agg({\n",
    "            'total_trips': 'mean',\n",
    "            'unique_plazas': 'mean',\n",
    "            'trips_per_hour': 'mean',\n",
    "            'avg_amount_per_trip': 'mean',\n",
    "            'plaza_to_trip_ratio': 'mean',\n",
    "            'total_amount': 'count'  # Just count the rows instead of using the vehicle column\n",
    "        })\n",
    "        \n",
    "        # Rename the count column to 'vehicle_count'\n",
    "        kmeans_cluster_stats = kmeans_cluster_stats.rename(columns={'total_amount': 'vehicle_count'})\n",
    "        \n",
    "        print(\"\\nK-Means Cluster statistics:\")\n",
    "        print(kmeans_cluster_stats)\n",
    "        \n",
    "        # Identify potential toll skipping clusters\n",
    "        toll_skip_score = kmeans_cluster_stats['plaza_to_trip_ratio'] \n",
    "        potential_skip_cluster = toll_skip_score.idxmin()\n",
    "        \n",
    "        print(f\"\\nPotential toll skipping K-Means cluster identified: Cluster {potential_skip_cluster}\")\n",
    "        print(f\"This cluster has {kmeans_cluster_stats.loc[potential_skip_cluster, 'vehicle_count']} vehicles\")\n",
    "        \n",
    "        # Get vehicles in the potential toll skipping cluster from KMeans\n",
    "        kmeans_skip_vehicles = multi_trip_vehicles[multi_trip_vehicles['kmeans_cluster'] == potential_skip_cluster]\n",
    "        \n",
    "        # Analyze DBSCAN outliers (cluster -1)\n",
    "        if -1 in multi_trip_vehicles['dbscan_cluster'].unique():\n",
    "            dbscan_outliers = multi_trip_vehicles[multi_trip_vehicles['dbscan_cluster'] == -1]\n",
    "            print(f\"\\nDBSCAN identified {len(dbscan_outliers)} potential outlier vehicles\")\n",
    "            \n",
    "            # Combine results from both methods\n",
    "            combined_suspects = pd.Index(list(set(kmeans_skip_vehicles.index) | set(dbscan_outliers.index)))\n",
    "            print(f\"\\nCombined unique suspect vehicles from both methods: {len(combined_suspects)}\")\n",
    "            \n",
    "            # Create a combined anomaly score\n",
    "            multi_trip_vehicles['combined_score'] = 0\n",
    "            multi_trip_vehicles.loc[multi_trip_vehicles['kmeans_cluster'] == potential_skip_cluster, 'combined_score'] += 1\n",
    "            multi_trip_vehicles.loc[multi_trip_vehicles['dbscan_cluster'] == -1, 'combined_score'] += 1\n",
    "            \n",
    "            # Get the most suspicious vehicles (detected by both methods)\n",
    "            high_confidence_suspects = multi_trip_vehicles[multi_trip_vehicles['combined_score'] > 1]\n",
    "            print(f\"High confidence suspects (detected by both methods): {len(high_confidence_suspects)}\")\n",
    "            \n",
    "            return high_confidence_suspects, models, scaler\n",
    "        else:\n",
    "            print(\"DBSCAN did not identify any outliers\")\n",
    "            return kmeans_skip_vehicles, models, scaler\n",
    "    else:\n",
    "        print(\"Not enough multi-trip vehicles to perform clustering\")\n",
    "        return None, None, None\n",
    "\n",
    "# Detect potential toll skipping\n",
    "print(\"\\nDetecting potential toll skipping patterns...\")\n",
    "potential_skip_vehicles, skip_models, skip_scaler = detect_potential_toll_skipping(df)\n",
    "\n",
    "if potential_skip_vehicles is not None and len(potential_skip_vehicles) > 0:\n",
    "    print(\"\\nSample of potential toll skipping vehicles:\")\n",
    "    print(potential_skip_vehicles.head())\n",
    "    \n",
    "    # Create a vehicle behavior classifier\n",
    "    print(\"\\n3.3 Building supervised vehicle behavior classifier\")\n",
    "    \n",
    "    # Use our detected vehicles to create a synthetic labeled dataset\n",
    "    print(\"Creating synthetic labeled dataset for demonstration...\")\n",
    "    \n",
    "    # Extract features from all multi-trip vehicles - use the index directly\n",
    "    all_vehicles = potential_skip_vehicles.copy()\n",
    "    \n",
    "    # Create more \"normal\" vehicles by slightly modifying the suspicious ones\n",
    "    normal_vehicles = potential_skip_vehicles.copy()\n",
    "    # Make them less suspicious by increasing plaza_to_trip_ratio\n",
    "    normal_vehicles['plaza_to_trip_ratio'] = normal_vehicles['plaza_to_trip_ratio'] * 1.5\n",
    "    normal_vehicles.index = [f\"normal_{idx}\" for idx in normal_vehicles.index]\n",
    "    \n",
    "    all_vehicles = pd.concat([all_vehicles, normal_vehicles])\n",
    "    \n",
    "    # Create labels (1 for suspicious, 0 for normal)\n",
    "    all_vehicles['label'] = 0\n",
    "    all_vehicles.loc[potential_skip_vehicles.index, 'label'] = 1\n",
    "    \n",
    "    # Extract features\n",
    "    X = all_vehicles[['total_trips', 'unique_plazas', 'trips_per_hour', \n",
    "                     'avg_amount_per_trip', 'plaza_to_trip_ratio']]\n",
    "    y = all_vehicles['label']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train a RandomForest classifier\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the classifier\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    print(\"\\nVehicle behavior classifier metrics:\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': rf_classifier.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature importance for detecting suspicious vehicles:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance for Suspicious Vehicle Detection')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/feature_importance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Save the classifier\n",
    "    vehicle_classifier = rf_classifier\n",
    "else:\n",
    "    print(\"No potential toll skipping vehicles detected. Skipping classifier creation.\")\n",
    "\n",
    "# 3.4 Enhanced Traffic Pattern Analysis\n",
    "print(\"\\n3.4 Enhanced Traffic Pattern Analysis\")\n",
    "\n",
    "def analyze_traffic_patterns_with_anomalies(features):\n",
    "    \"\"\"Analyze traffic patterns incorporating anomaly information.\"\"\"\n",
    "    # Group by hour of day\n",
    "    hourly_patterns = features.groupby('hour').agg({\n",
    "        'transaction_count': 'mean',\n",
    "        'ensemble_is_anomaly': 'mean'  # Gives the proportion of anomalies by hour\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Group by day of week\n",
    "    daily_patterns = features.groupby('day_of_week').agg({\n",
    "        'transaction_count': 'mean',\n",
    "        'ensemble_is_anomaly': 'mean'  # Gives the proportion of anomalies by day\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Visualize hourly patterns\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.bar(hourly_patterns['hour'], hourly_patterns['transaction_count'])\n",
    "    plt.title('Average Transactions by Hour of Day')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Average Transaction Count')\n",
    "    plt.xticks(range(0, 24, 2))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.bar(hourly_patterns['hour'], hourly_patterns['ensemble_is_anomaly'] * 100)\n",
    "    plt.title('Percentage of Anomalies by Hour of Day')\n",
    "    plt.xlabel('Hour of Day')\n",
    "    plt.ylabel('Anomaly Percentage')\n",
    "    plt.xticks(range(0, 24, 2))\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    plt.bar(days, daily_patterns['transaction_count'])\n",
    "    plt.title('Average Transactions by Day of Week')\n",
    "    plt.xlabel('Day of Week')\n",
    "    plt.ylabel('Average Transaction Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.bar(days, daily_patterns['ensemble_is_anomaly'] * 100)\n",
    "    plt.title('Percentage of Anomalies by Day of Week')\n",
    "    plt.xlabel('Day of Week')\n",
    "    plt.ylabel('Anomaly Percentage')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/traffic_pattern_analysis.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Find the most anomalous hours and days\n",
    "    most_anomalous_hours = hourly_patterns.sort_values('ensemble_is_anomaly', ascending=False)[['hour', 'ensemble_is_anomaly']].head(3)\n",
    "    most_anomalous_days = daily_patterns.sort_values('ensemble_is_anomaly', ascending=False)[['day_of_week', 'ensemble_is_anomaly']].head(3)\n",
    "    \n",
    "    print(\"\\nMost anomalous hours of the day:\")\n",
    "    for _, row in most_anomalous_hours.iterrows():\n",
    "        print(f\"Hour {int(row['hour'])}: {row['ensemble_is_anomaly']*100:.2f}% anomalies\")\n",
    "    \n",
    "    print(\"\\nMost anomalous days of the week:\")\n",
    "    day_names = {0: 'Monday', 1: 'Tuesday', 2: 'Wednesday', 3: 'Thursday', 4: 'Friday', 5: 'Saturday', 6: 'Sunday'}\n",
    "    for _, row in most_anomalous_days.iterrows():\n",
    "        day = day_names[row['day_of_week']]\n",
    "        print(f\"{day}: {row['ensemble_is_anomaly']*100:.2f}% anomalies\")\n",
    "    \n",
    "    return hourly_patterns, daily_patterns\n",
    "\n",
    "# Analyze traffic patterns including anomaly information\n",
    "if 'features_with_anomalies' in locals():\n",
    "    print(\"\\nAnalyzing traffic patterns with anomaly information...\")\n",
    "    hourly_patterns, daily_patterns = analyze_traffic_patterns_with_anomalies(features_with_anomalies)\n",
    "\n",
    "# 4. SAVE MODELS AND RESULTS\n",
    "print(\"\\n4. SAVING MODELS AND RESULTS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Save traffic prediction model\n",
    "if 'traffic_model' in locals():\n",
    "    joblib.dump(traffic_model, 'models/traffic_prediction_model.pkl')\n",
    "    print(\"Traffic prediction model saved as 'traffic_prediction_model.pkl'\")\n",
    "\n",
    "# Save anomaly detection models\n",
    "if 'anomaly_models' in locals():\n",
    "    joblib.dump((anomaly_models, anomaly_scaler), 'models/traffic_anomaly_models.pkl')\n",
    "    print(\"Traffic anomaly detection models saved as 'traffic_anomaly_models.pkl'\")\n",
    "\n",
    "# Save vehicle class prediction model if available\n",
    "if 'vc_model' in locals():\n",
    "    joblib.dump(vc_model, 'models/vehicle_class_prediction_model.pkl')\n",
    "    print(\"Vehicle class prediction model saved as 'vehicle_class_prediction_model.pkl'\")\n",
    "\n",
    "# Save toll skipping detection models if available\n",
    "if 'skip_models' in locals() and skip_models is not None:\n",
    "    joblib.dump((skip_models, skip_scaler), 'models/toll_skipping_models.pkl')\n",
    "    print(\"Toll skipping detection models saved as 'toll_skipping_models.pkl'\")\n",
    "\n",
    "# Save vehicle behavior classifier if available\n",
    "if 'vehicle_classifier' in locals():\n",
    "    joblib.dump(vehicle_classifier, 'models/vehicle_behavior_classifier.pkl')\n",
    "    print(\"Vehicle behavior classifier saved as 'vehicle_behavior_classifier.pkl'\")\n",
    "\n",
    "# Save the anomalies dataframe\n",
    "if 'anomalies' in locals() and len(anomalies) > 0:\n",
    "    anomalies.to_csv('data/detected_anomalies.csv', index=False)\n",
    "    print(\"Detected anomalies saved as 'detected_anomalies.csv'\")\n",
    "\n",
    "# Save potential toll skipping vehicles\n",
    "if 'potential_skip_vehicles' in locals() and potential_skip_vehicles is not None:\n",
    "    potential_skip_vehicles.to_csv('data/potential_toll_skipping_vehicles.csv')\n",
    "    print(\"Potential toll skipping vehicles saved as 'potential_toll_skipping_vehicles.csv'\")\n",
    "\n",
    "# Save traffic pattern analysis results\n",
    "if 'hourly_patterns' in locals() and 'daily_patterns' in locals():\n",
    "    hourly_patterns.to_csv('data/hourly_traffic_patterns.csv', index=False)\n",
    "    daily_patterns.to_csv('data/daily_traffic_patterns.csv', index=False)\n",
    "    print(\"Traffic pattern analysis results saved as CSV files\")\n",
    "\n",
    "print(\"\\nPhase 2: Enhanced Analytics Models complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
