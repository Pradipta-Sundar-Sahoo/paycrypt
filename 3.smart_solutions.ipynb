{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import datetime\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import uuid\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import pickle\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import re\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "import networkx as nx\n",
    "import folium\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 3: Smart Solutions Implementation...\n",
      "\n",
      "1. LOADING DATA AND MODELS\n",
      "--------------------------------------------------\n",
      "Data loaded with 367074 records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting Phase 3: Smart Solutions Implementation...\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. LOAD DATA AND MODELS\n",
    "# =============================================================================\n",
    "print(\"\\n1. LOADING DATA AND MODELS\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_csv('data/preprocessed_tollplaza_data.csv')\n",
    "df['initiated_time'] = pd.to_datetime(df['initiated_time'])\n",
    "df['time_interval'] = pd.to_datetime(df['time_interval'])\n",
    "\n",
    "# Load models\n",
    "traffic_model = joblib.load('models/traffic_prediction_model.pkl')\n",
    "anomaly_model, anomaly_scaler = joblib.load('models/traffic_anomaly_models.pkl')\n",
    "\n",
    "# Try to load other models if they exist\n",
    "try:\n",
    "    vc_model = joblib.load('models/vehicle_class_prediction_model.pkl')\n",
    "    vc_model_loaded = True\n",
    "except:\n",
    "    vc_model_loaded = False\n",
    "    print(\"Vehicle class model not found, skipping...\")\n",
    "\n",
    "try:\n",
    "    skip_model, skip_scaler = joblib.load('models/toll_skipping_models.pkl')\n",
    "    skip_model_loaded = True\n",
    "except:\n",
    "    skip_model_loaded = False\n",
    "    print(\"Toll skipping model not found, skipping...\")\n",
    "\n",
    "print(f\"Data loaded with {df.shape[0]} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. LANE OPTIMIZATION SYSTEM\n",
      "--------------------------------------------------\n",
      "Lane recommendations for Devanahalli Toll Plaza at 8:00:\n",
      "{\n",
      "  \"plaza\": \"Devanahalli Toll Plaza\",\n",
      "  \"hour\": 8,\n",
      "  \"expected_traffic\": 3656,\n",
      "  \"lanes_needed\": 37,\n",
      "  \"commercial_ratio\": 0.24699124726477023,\n",
      "  \"recommended_lanes\": [\n",
      "    {\n",
      "      \"lane\": \"15\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 172.7101171458999\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"16\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 146.7950024260068\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"14\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 164.6748046875\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"5\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 178.58856191004998\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"4\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 201.40320765334835\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"13\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 210.99536178107607\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"17\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 331.69315326633165\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"18\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 151.23050095117313\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"8\",\n",
      "      \"role\": \"Commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 231.17530140110784\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"12\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 190.78646517739816\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 15,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 160.3962641761174\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"7\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 254.56372218476062\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 16,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 130.01327769347498\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 14,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 135.08233009708738\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"2\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 174.781990521327\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"3\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 236.05408805031448\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"9\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 225.44209636517328\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 5,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 225.7092665788318\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 4,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 158.72906178489703\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 17,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 341.1147776183644\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 13,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 175.56069364161849\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 12,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 204.64171897633994\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"6\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 190.84070796460176\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 8,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 337.5933842239186\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 18,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 144.4778578784758\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 7,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 236.2694840834248\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 2,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 254.82395644283122\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"19\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 171.19322459222082\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 9,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 284.42857142857144\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 3,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 337.259649122807\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 6,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 168.2185582822086\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 19,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 183.38957345971565\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"1\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 255.90424242424243\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 1,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 300.085409252669\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"20\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 180.94389438943895\n",
      "    },\n",
      "    {\n",
      "      \"lane\": 20,\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 300.19069767441863\n",
      "    },\n",
      "    {\n",
      "      \"lane\": \"33\",\n",
      "      \"role\": \"Non-commercial\",\n",
      "      \"expected_volume\": 98,\n",
      "      \"processing_time\": 145.3109756097561\n",
      "    }\n",
      "  ],\n",
      "  \"vehicle_distribution\": {\n",
      "    \"VC4\": 0.8432713347921226,\n",
      "    \"VC7\": 0.053610503282275714,\n",
      "    \"VC20\": 0.026805251641137857,\n",
      "    \"VC5\": 0.02598468271334792,\n",
      "    \"VC10\": 0.013402625820568928,\n",
      "    \"VC12\": 0.010393873085339168,\n",
      "    \"VC11\": 0.009026258205689279,\n",
      "    \"VC9\": 0.007111597374179431,\n",
      "    \"VC13\": 0.0057439824945295405,\n",
      "    \"VC8\": 0.002461706783369803,\n",
      "    \"VC14\": 0.002188183807439825\n",
      "  },\n",
      "  \"historical_average_processing_time\": 176.9789387308534\n",
      "}\n",
      "\n",
      "Dynamic pricing recommendations for Devanahalli Toll Plaza at 8:00:\n",
      "{\n",
      "  \"plaza\": \"Devanahalli Toll Plaza\",\n",
      "  \"hour\": 8,\n",
      "  \"congestion_level\": 0.7615080191626744,\n",
      "  \"current_pricing\": {\n",
      "    \"VC10\": 355.0,\n",
      "    \"VC11\": 540.0,\n",
      "    \"VC12\": 540.0,\n",
      "    \"VC13\": 540.0,\n",
      "    \"VC14\": 540.0,\n",
      "    \"VC20\": 115.0,\n",
      "    \"VC4\": 115.0,\n",
      "    \"VC5\": 175.0,\n",
      "    \"VC7\": 355.0,\n",
      "    \"VC8\": 540.0,\n",
      "    \"VC9\": 175.0\n",
      "  },\n",
      "  \"recommended_pricing\": {\n",
      "    \"VC10\": 369.56,\n",
      "    \"VC11\": 562.14,\n",
      "    \"VC12\": 562.14,\n",
      "    \"VC13\": 562.14,\n",
      "    \"VC14\": 562.14,\n",
      "    \"VC20\": 119.72,\n",
      "    \"VC4\": 119.72,\n",
      "    \"VC5\": 182.18,\n",
      "    \"VC7\": 369.56,\n",
      "    \"VC8\": 562.14,\n",
      "    \"VC9\": 182.18\n",
      "  },\n",
      "  \"expected_impact\": {\n",
      "    \"revenue_change\": \"4.10%\",\n",
      "    \"expected_traffic_reduction\": \"1.31%\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 2. LANE OPTIMIZATION SYSTEM\n",
    "# =============================================================================\n",
    "print(\"\\n2. LANE OPTIMIZATION SYSTEM\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "class LaneOptimizationSystem:\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.plaza_lanes = self._get_plaza_lanes()\n",
    "        self.vehicle_types = sorted(self.df['vehicle_class_code'].unique())\n",
    "        self.lane_efficiency = self._calculate_lane_efficiency()\n",
    "        \n",
    "    def _get_plaza_lanes(self) -> Dict[str, List[str]]:\n",
    "        plaza_lanes = {}\n",
    "        \n",
    "        for plaza in self.df['merchant_name'].unique():\n",
    "            lanes = self.df[self.df['merchant_name'] == plaza]['lane'].unique()\n",
    "            plaza_lanes[plaza] = sorted(lanes, key=lambda x: (isinstance(x, str), x))\n",
    "        return plaza_lanes\n",
    "        \n",
    "    def _calculate_lane_efficiency(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate efficiency of each lane.\"\"\"\n",
    "        lane_stats = self.df.groupby(['merchant_name', 'lane'])['inn_rr_time_sec'].agg([\n",
    "            'mean', 'count', 'std'\n",
    "        ]).reset_index()\n",
    "        lane_stats.columns = ['plaza', 'lane', 'avg_processing_time', 'volume', 'time_std']\n",
    "        \n",
    "        # Normalize and compute a weighted efficiency score (lower is better)\n",
    "        scaler = MinMaxScaler()\n",
    "        lane_stats[['norm_time', 'norm_volume']] = scaler.fit_transform(\n",
    "            lane_stats[['avg_processing_time', 'volume']])\n",
    "        \n",
    "        lane_stats['efficiency_score'] = 0.7 * lane_stats['norm_time'] - 0.3 * lane_stats['norm_volume']\n",
    "        return lane_stats\n",
    "    \n",
    "    def get_lane_recommendations(self, plaza: str, hour: int, expected_traffic: int = None) -> Dict[str, Any]:\n",
    "\n",
    "        # Filter for specific plaza\n",
    "        plaza_data = self.df[self.df['merchant_name'] == plaza].copy()\n",
    "        if plaza_data.empty:\n",
    "            return {\"error\": f\"No data available for plaza {plaza}\"}\n",
    "        \n",
    "        # Get available lanes\n",
    "        available_lanes = self.plaza_lanes.get(plaza, [])\n",
    "        if not available_lanes:\n",
    "            return {\"error\": f\"No lanes data available for plaza {plaza}\"}\n",
    "        \n",
    "        # Get historical traffic patterns for this hour\n",
    "        hourly_data = plaza_data[plaza_data['initiated_time'].dt.hour == hour]\n",
    "        if hourly_data.empty:\n",
    "            return {\"error\": f\"No data available for plaza {plaza} at hour {hour}\"}\n",
    "        \n",
    "        # Convert 'vehicle_comvehicle' to numeric if present\n",
    "        if 'vehicle_comvehicle' in hourly_data.columns:\n",
    "            # Replace 'F' with 0 and 'T' with 1; non-convertible values become NaN\n",
    "            hourly_data['vehicle_comvehicle'] = pd.to_numeric(\n",
    "                hourly_data['vehicle_comvehicle'].replace({'F': 0, 'T': 1}),\n",
    "                errors='coerce'\n",
    "            )\n",
    "            commercial_ratio = hourly_data['vehicle_comvehicle'].mean()\n",
    "            if pd.isna(commercial_ratio):\n",
    "                commercial_ratio = 0.3\n",
    "        else:\n",
    "            commercial_ratio = 0.3\n",
    "        \n",
    "        # Get vehicle distribution for this hour\n",
    "        vehicle_dist = hourly_data['vehicle_class_code'].value_counts(normalize=True)\n",
    "        \n",
    "        # Get lane efficiency for this plaza\n",
    "        plaza_efficiency = self.lane_efficiency[self.lane_efficiency['plaza'] == plaza].copy()\n",
    "        \n",
    "        # Calculate needed lanes based on historical or expected traffic\n",
    "        if expected_traffic is None:\n",
    "            expected_traffic = len(hourly_data)\n",
    "        \n",
    "        lanes_needed = max(2, int(np.ceil(expected_traffic / 100)))\n",
    "        lanes_needed = min(lanes_needed, len(available_lanes))  # Can't open more lanes than available\n",
    "        \n",
    "        # Select the most efficient lanes\n",
    "        best_lanes = plaza_efficiency.sort_values('efficiency_score').head(lanes_needed)\n",
    "        \n",
    "        # Determine which lanes to allocate for commercial vehicles\n",
    "        commercial_lanes = max(1, int(np.round(commercial_ratio * lanes_needed)))\n",
    "        \n",
    "        # Sort lanes by efficiency and assign roles\n",
    "        recommended_lanes = []\n",
    "        for i, (_, lane_data) in enumerate(best_lanes.iterrows()):\n",
    "            lane_role = \"Commercial\" if i < commercial_lanes else \"Non-commercial\"\n",
    "            recommended_lanes.append({\n",
    "                \"lane\": lane_data['lane'],\n",
    "                \"role\": lane_role,\n",
    "                \"expected_volume\": int(expected_traffic / lanes_needed),\n",
    "                \"processing_time\": float(lane_data['avg_processing_time'])\n",
    "            })\n",
    "        \n",
    "        # Prepare recommendations\n",
    "        recommendations = {\n",
    "            \"plaza\": plaza,\n",
    "            \"hour\": hour,\n",
    "            \"expected_traffic\": expected_traffic,\n",
    "            \"lanes_needed\": lanes_needed,\n",
    "            \"commercial_ratio\": float(commercial_ratio),\n",
    "            \"recommended_lanes\": recommended_lanes,\n",
    "            \"vehicle_distribution\": {k: float(v) for k, v in vehicle_dist.items()},\n",
    "            \"historical_average_processing_time\": float(hourly_data['inn_rr_time_sec'].mean())\n",
    "        }\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "    \n",
    "    def get_dynamic_pricing_recommendations(self, plaza: str, hour: int) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get dynamic pricing recommendations for a specific plaza and time.\n",
    "        \"\"\"\n",
    "        plaza_data = self.df[self.df['merchant_name'] == plaza].copy()\n",
    "        if plaza_data.empty:\n",
    "            return {\"error\": f\"No data available for plaza {plaza}\"}\n",
    "            \n",
    "        hourly_data = plaza_data[plaza_data['initiated_time'].dt.hour == hour]\n",
    "        if hourly_data.empty:\n",
    "            return {\"error\": f\"No data available for plaza {plaza} at hour {hour}\"}\n",
    "        \n",
    "        max_hourly_traffic = plaza_data.groupby(plaza_data['initiated_time'].dt.hour).size().max()\n",
    "        current_hourly_traffic = len(hourly_data)\n",
    "        congestion_level = current_hourly_traffic / max_hourly_traffic if max_hourly_traffic > 0 else 0\n",
    "        \n",
    "        current_pricing = {}\n",
    "        for vc in self.vehicle_types:\n",
    "            vc_data = hourly_data[hourly_data['vehicle_class_code'] == vc]\n",
    "            if not vc_data.empty:\n",
    "                current_pricing[vc] = float(vc_data['txn_amount'].median())\n",
    "        \n",
    "        recommended_pricing = {}\n",
    "        for vc, base_price in current_pricing.items():\n",
    "            if congestion_level > 0.7:  # High congestion: increase up to 20%\n",
    "                factor = 1.0 + (congestion_level - 0.7) * (0.2 / 0.3)\n",
    "            elif congestion_level < 0.3:  # Low congestion: decrease up to 10%\n",
    "                factor = 1.0 - (0.3 - congestion_level) * (0.1 / 0.3)\n",
    "            else:\n",
    "                factor = 1.0\n",
    "            recommended_pricing[vc] = round(base_price * factor, 2)\n",
    "        \n",
    "        recommendations = {\n",
    "            \"plaza\": plaza,\n",
    "            \"hour\": hour,\n",
    "            \"congestion_level\": float(congestion_level),\n",
    "            \"current_pricing\": current_pricing,\n",
    "            \"recommended_pricing\": recommended_pricing,\n",
    "            \"expected_impact\": {\n",
    "                \"revenue_change\": f\"{(sum(recommended_pricing.values()) - sum(current_pricing.values())) / sum(current_pricing.values()) * 100:.2f}%\",\n",
    "                \"expected_traffic_reduction\": f\"{5 * (congestion_level - 0.5) if congestion_level > 0.5 else 0:.2f}%\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def visualize_lane_recommendations(self, plaza: str, hour: int) -> Dict[str, Any]:\n",
    "    \n",
    "        recommendations = self.get_lane_recommendations(plaza, hour)\n",
    "        if \"error\" in recommendations:\n",
    "            return {\"error\": recommendations[\"error\"]}\n",
    "        \n",
    "        viz_data = {\n",
    "            \"plaza\": plaza,\n",
    "            \"hour\": hour,\n",
    "            \"lane_allocation\": {\n",
    "                \"lanes\": [lane[\"lane\"] for lane in recommendations[\"recommended_lanes\"]],\n",
    "                \"roles\": [lane[\"role\"] for lane in recommendations[\"recommended_lanes\"]],\n",
    "                \"volumes\": [lane[\"expected_volume\"] for lane in recommendations[\"recommended_lanes\"]]\n",
    "            },\n",
    "            \"vehicle_distribution\": recommendations[\"vehicle_distribution\"]\n",
    "        }\n",
    "        \n",
    "        return viz_data\n",
    "\n",
    "# Initialize lane optimization system\n",
    "lane_optimizer = LaneOptimizationSystem(df)\n",
    "\n",
    "# Example usage for lane optimization\n",
    "plaza_example = df['merchant_name'].value_counts().index[0]  # Most common plaza\n",
    "hour_example = 8  # Example hour\n",
    "\n",
    "lane_recommendations = lane_optimizer.get_lane_recommendations(plaza_example, hour_example)\n",
    "print(f\"Lane recommendations for {plaza_example} at {hour_example}:00:\")\n",
    "print(json.dumps(lane_recommendations, indent=2))\n",
    "\n",
    "pricing_recommendations = lane_optimizer.get_dynamic_pricing_recommendations(plaza_example, hour_example)\n",
    "print(f\"\\nDynamic pricing recommendations for {plaza_example} at {hour_example}:00:\")\n",
    "print(json.dumps(pricing_recommendations, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. LANE OPTIMIZATION SYSTEM WITH OPENAI ENHANCEMENT\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import openai\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "class EnhancedLaneOptimizationSystem:\n",
    "    def __init__(self, data, openai_api_key=None):\n",
    "        self.df = data\n",
    "        self.plaza_lanes = self._get_plaza_lanes()\n",
    "        self.vehicle_types = sorted(self.df['vehicle_class_code'].unique())\n",
    "        self.lane_efficiency = self._calculate_lane_efficiency()\n",
    "        \n",
    "        # Configure OpenAI client\n",
    "        self.openai_api_key = openai_api_key or os.environ.get(\"OPENAI_API_KEY\")\n",
    "        if self.openai_api_key:\n",
    "            self.client = openai.OpenAI(api_key=self.openai_api_key)\n",
    "        else:\n",
    "            print(\"Warning: No OpenAI API key provided. Advanced recommendations will be limited.\")\n",
    "            self.client = None\n",
    "        \n",
    "        # Create historical patterns cache for faster lookups\n",
    "        self.historical_patterns = self._analyze_historical_patterns()\n",
    "        \n",
    "    def _get_plaza_lanes(self) -> Dict[str, List[str]]:\n",
    "        plaza_lanes = {}\n",
    "        \n",
    "        for plaza in self.df['merchant_name'].unique():\n",
    "            lanes = self.df[self.df['merchant_name'] == plaza]['lane'].unique()\n",
    "            plaza_lanes[plaza] = sorted(lanes, key=lambda x: (isinstance(x, str), x))\n",
    "        return plaza_lanes\n",
    "        \n",
    "    def _calculate_lane_efficiency(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate efficiency of each lane with enhanced metrics.\"\"\"\n",
    "        lane_stats = self.df.groupby(['merchant_name', 'lane']).agg({\n",
    "            'inn_rr_time_sec': ['mean', 'count', 'std'],\n",
    "            'txn_amount': ['mean']\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Flatten multi-level columns\n",
    "        lane_stats.columns = ['plaza', 'lane', 'avg_processing_time', 'volume', 'time_std', 'avg_revenue']\n",
    "        \n",
    "        # Add day of week and hour analysis for each lane\n",
    "        time_patterns = self.df.groupby(['merchant_name', 'lane', \n",
    "                                         self.df['initiated_time'].dt.day_name(),\n",
    "                                         self.df['initiated_time'].dt.hour])['inn_rr_time_sec'].mean()\n",
    "        \n",
    "        # Find busiest periods\n",
    "        lane_stats['peak_periods'] = lane_stats.apply(\n",
    "            lambda x: self._find_peak_periods(x['plaza'], x['lane']), axis=1\n",
    "        )\n",
    "        \n",
    "        # Normalize and compute a weighted efficiency score (lower is better)\n",
    "        scaler = MinMaxScaler()\n",
    "        lane_stats[['norm_time', 'norm_volume', 'norm_revenue']] = scaler.fit_transform(\n",
    "            lane_stats[['avg_processing_time', 'volume', 'avg_revenue']])\n",
    "        \n",
    "        # Enhanced efficiency score: considers processing time, volume, and revenue\n",
    "        lane_stats['efficiency_score'] = (\n",
    "            0.5 * lane_stats['norm_time'] - \n",
    "            0.3 * lane_stats['norm_volume'] - \n",
    "            0.2 * lane_stats['norm_revenue']\n",
    "        )\n",
    "        \n",
    "        # Calculate reliability score (lower std deviation = more reliable)\n",
    "        max_std = lane_stats['time_std'].max()\n",
    "        if max_std > 0:\n",
    "            lane_stats['reliability_score'] = 1 - (lane_stats['time_std'] / max_std)\n",
    "        else:\n",
    "            lane_stats['reliability_score'] = 1.0\n",
    "            \n",
    "        return lane_stats\n",
    "    \n",
    "    def _find_peak_periods(self, plaza, lane):\n",
    "        \"\"\"Find peak busy periods for a specific lane.\"\"\"\n",
    "        lane_data = self.df[(self.df['merchant_name'] == plaza) & \n",
    "                             (self.df['lane'] == lane)]\n",
    "        \n",
    "        if lane_data.empty:\n",
    "            return []\n",
    "            \n",
    "        # Group by day of week and hour\n",
    "        hourly_counts = lane_data.groupby([\n",
    "            lane_data['initiated_time'].dt.day_name(),\n",
    "            lane_data['initiated_time'].dt.hour\n",
    "        ]).size()\n",
    "        \n",
    "        # Get top 3 busiest periods\n",
    "        if len(hourly_counts) > 0:\n",
    "            top_periods = hourly_counts.nlargest(3)\n",
    "            return [{\"day\": day, \"hour\": hour, \"volume\": int(count)} \n",
    "                    for (day, hour), count in top_periods.items()]\n",
    "        return []\n",
    "    \n",
    "    def _analyze_historical_patterns(self):\n",
    "        \"\"\"Create a cache of historical traffic patterns for faster lookups.\"\"\"\n",
    "        patterns = {}\n",
    "        \n",
    "        for plaza in self.df['merchant_name'].unique():\n",
    "            plaza_data = self.df[self.df['merchant_name'] == plaza]\n",
    "            patterns[plaza] = {}\n",
    "            \n",
    "            # Analyze by hour of day\n",
    "            for hour in range(24):\n",
    "                hour_data = plaza_data[plaza_data['initiated_time'].dt.hour == hour]\n",
    "                if not hour_data.empty:\n",
    "                    patterns[plaza][hour] = {\n",
    "                        'avg_traffic': len(hour_data),\n",
    "                        'vehicle_distribution': dict(hour_data['vehicle_class_code'].value_counts(normalize=True)),\n",
    "                        'avg_processing_time': float(hour_data['inn_rr_time_sec'].mean()),\n",
    "                        'commercial_ratio': float(hour_data['vehicle_comvehicle'].replace(\n",
    "                            {'F': 0, 'T': 1}).mean()) if 'vehicle_comvehicle' in hour_data.columns else 0.3\n",
    "                    }\n",
    "        \n",
    "        return patterns\n",
    "    \n",
    "    def get_lane_recommendations(self, plaza: str, hour: int, expected_traffic: int = None,\n",
    "                                use_ai: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get lane recommendations with enhanced AI-based optimization when available.\n",
    "        \n",
    "        Args:\n",
    "            plaza: The toll plaza name\n",
    "            hour: Hour of day (0-23)\n",
    "            expected_traffic: Expected traffic volume (if None, uses historical data)\n",
    "            use_ai: Whether to use OpenAI for enhanced recommendations\n",
    "        \"\"\"\n",
    "        # First check if we have historical data for this plaza and hour\n",
    "        if plaza not in self.historical_patterns or hour not in self.historical_patterns[plaza]:\n",
    "            return {\"error\": f\"No historical data available for plaza {plaza} at hour {hour}\"}\n",
    "        \n",
    "        # Get historical pattern data\n",
    "        historical = self.historical_patterns[plaza][hour]\n",
    "        \n",
    "        # Get available lanes\n",
    "        available_lanes = self.plaza_lanes.get(plaza, [])\n",
    "        if not available_lanes:\n",
    "            return {\"error\": f\"No lanes data available for plaza {plaza}\"}\n",
    "        \n",
    "        # Use historical or provided expected traffic\n",
    "        if expected_traffic is None:\n",
    "            expected_traffic = historical['avg_traffic']\n",
    "        \n",
    "        # Get plaza efficiency data\n",
    "        plaza_efficiency = self.lane_efficiency[self.lane_efficiency['plaza'] == plaza].copy()\n",
    "        if plaza_efficiency.empty:\n",
    "            return {\"error\": f\"No efficiency data available for plaza {plaza}\"}\n",
    "        \n",
    "        # Calculate recommended number of lanes based on traffic\n",
    "        recommended_lanes_count = max(2, int(np.ceil(expected_traffic / 100)))\n",
    "        recommended_lanes_count = min(recommended_lanes_count, len(available_lanes))\n",
    "        \n",
    "        # Get AI-enhanced recommendations if available and requested\n",
    "        if use_ai and self.client:\n",
    "            ai_recommendations = self._get_ai_lane_recommendations(\n",
    "                plaza, hour, expected_traffic, recommended_lanes_count, \n",
    "                historical, plaza_efficiency, available_lanes\n",
    "            )\n",
    "            if ai_recommendations and \"error\" not in ai_recommendations:\n",
    "                return ai_recommendations\n",
    "        \n",
    "        # Fall back to standard algorithm if AI is not available or fails\n",
    "        # Select most efficient lanes\n",
    "        best_lanes = plaza_efficiency.sort_values(['efficiency_score', 'reliability_score'], \n",
    "                                                ascending=[True, False]).head(recommended_lanes_count)\n",
    "        \n",
    "        # Calculate commercial lanes based on historical ratio\n",
    "        commercial_ratio = historical['commercial_ratio']\n",
    "        commercial_lanes = max(1, int(np.round(commercial_ratio * recommended_lanes_count)))\n",
    "        \n",
    "        # Allocate lanes\n",
    "        recommended_lanes = []\n",
    "        for i, (_, lane_data) in enumerate(best_lanes.iterrows()):\n",
    "            lane_role = \"Commercial\" if i < commercial_lanes else \"Non-commercial\"\n",
    "            recommended_lanes.append({\n",
    "                \"lane\": lane_data['lane'],\n",
    "                \"role\": lane_role,\n",
    "                \"expected_volume\": int(expected_traffic / recommended_lanes_count),\n",
    "                \"processing_time\": float(lane_data['avg_processing_time']),\n",
    "                \"reliability\": float(lane_data['reliability_score']),\n",
    "                \"peak_periods\": lane_data['peak_periods']\n",
    "            })\n",
    "        \n",
    "        # Create recommendations output\n",
    "        recommendations = {\n",
    "            \"plaza\": plaza,\n",
    "            \"hour\": hour,\n",
    "            \"expected_traffic\": expected_traffic,\n",
    "            \"lanes_needed\": recommended_lanes_count,\n",
    "            \"commercial_ratio\": float(commercial_ratio),\n",
    "            \"recommended_lanes\": recommended_lanes,\n",
    "            \"vehicle_distribution\": historical['vehicle_distribution'],\n",
    "            \"historical_average_processing_time\": float(historical['avg_processing_time']),\n",
    "            \"ai_enhanced\": False,\n",
    "            \"recommendation_timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _get_ai_lane_recommendations(self, plaza, hour, expected_traffic, lanes_needed, \n",
    "                                    historical, plaza_efficiency, available_lanes):\n",
    "        \"\"\"Use OpenAI to generate enhanced lane recommendations.\"\"\"\n",
    "        try:\n",
    "            # Format the context for OpenAI to analyze\n",
    "            context = {\n",
    "                \"plaza\": plaza,\n",
    "                \"hour\": hour,\n",
    "                \"expected_traffic\": expected_traffic,\n",
    "                \"historical_avg_traffic\": historical['avg_traffic'],\n",
    "                \"commercial_ratio\": historical['commercial_ratio'],\n",
    "                \"available_lanes\": len(available_lanes),\n",
    "                \"lane_efficiency_data\": plaza_efficiency.to_dict(orient='records'),\n",
    "                \"vehicle_distribution\": historical['vehicle_distribution'],\n",
    "                \"avg_processing_time\": historical['avg_processing_time']\n",
    "            }\n",
    "            \n",
    "            # Get AI recommendation\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"\n",
    "                    You are an AI traffic optimization assistant specializing in toll plaza management.\n",
    "                    Analyze the provided toll plaza data and recommend the optimal lane allocation strategy.\n",
    "                    Your response should be a valid JSON object containing recommended lane allocations\n",
    "                    and expected performance metrics. Consider vehicle types, commercial vs non-commercial\n",
    "                    allocations, and processing efficiency. Apply traffic flow optimization principles.\n",
    "                    \"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                    Provide lane allocation recommendations for the following toll plaza situation:\n",
    "                    {json.dumps(context, indent=2)}\n",
    "                    \n",
    "                    Return a JSON with these fields:\n",
    "                    1. recommended_lanes: array of lane objects with lane id, role (Commercial/Non-commercial), expected_volume, and processing_time\n",
    "                    2. expected_wait_time: estimated average wait time in seconds\n",
    "                    3. optimization_notes: key insights about this allocation strategy\n",
    "                    \n",
    "                    Base your recommendations on efficiency scores (lower is better), reliability scores (higher is better),\n",
    "                    and intelligent distribution of commercial vs non-commercial traffic.\n",
    "                    \"\"\"} \n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Extract and parse recommendation\n",
    "            ai_recommendation = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Create the complete recommendation to return\n",
    "            recommendation = {\n",
    "                \"plaza\": plaza,\n",
    "                \"hour\": hour,\n",
    "                \"expected_traffic\": expected_traffic,\n",
    "                \"lanes_needed\": lanes_needed,\n",
    "                \"commercial_ratio\": float(historical['commercial_ratio']),\n",
    "                \"recommended_lanes\": ai_recommendation.get(\"recommended_lanes\", []),\n",
    "                \"vehicle_distribution\": historical['vehicle_distribution'],\n",
    "                \"historical_average_processing_time\": float(historical['avg_processing_time']),\n",
    "                \"ai_enhanced\": True,\n",
    "                \"expected_wait_time\": ai_recommendation.get(\"expected_wait_time\"),\n",
    "                \"optimization_notes\": ai_recommendation.get(\"optimization_notes\", []),\n",
    "                \"recommendation_timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            return recommendation\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting AI lane recommendations: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_dynamic_pricing_recommendations(self, plaza: str, hour: int, \n",
    "                                         use_ai: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get AI-enhanced dynamic pricing recommendations for a specific plaza and time.\n",
    "        \"\"\"\n",
    "        # Check if we have historical data\n",
    "        if plaza not in self.historical_patterns or hour not in self.historical_patterns[plaza]:\n",
    "            return {\"error\": f\"No historical data available for plaza {plaza} at hour {hour}\"}\n",
    "        \n",
    "        # Get historical pattern data\n",
    "        historical = self.historical_patterns[plaza][hour]\n",
    "        \n",
    "        # Get current pricing from historical data\n",
    "        plaza_data = self.df[self.df['merchant_name'] == plaza]\n",
    "        hourly_data = plaza_data[plaza_data['initiated_time'].dt.hour == hour]\n",
    "        \n",
    "        if hourly_data.empty:\n",
    "            return {\"error\": f\"No transaction data available for plaza {plaza} at hour {hour}\"}\n",
    "        \n",
    "        # Calculate congestion level\n",
    "        max_hourly_traffic = plaza_data.groupby(plaza_data['initiated_time'].dt.hour).size().max()\n",
    "        current_hourly_traffic = len(hourly_data)\n",
    "        congestion_level = current_hourly_traffic / max_hourly_traffic if max_hourly_traffic > 0 else 0\n",
    "        \n",
    "        # Get current pricing by vehicle type\n",
    "        current_pricing = {}\n",
    "        for vc in self.vehicle_types:\n",
    "            vc_data = hourly_data[hourly_data['vehicle_class_code'] == vc]\n",
    "            if not vc_data.empty:\n",
    "                current_pricing[vc] = float(vc_data['txn_amount'].median())\n",
    "        \n",
    "        # Get AI-enhanced pricing if available and requested\n",
    "        if use_ai and self.client:\n",
    "            ai_pricing = self._get_ai_pricing_recommendations(\n",
    "                plaza, hour, congestion_level, current_pricing, historical\n",
    "            )\n",
    "            if ai_pricing and \"error\" not in ai_pricing:\n",
    "                return ai_pricing\n",
    "                \n",
    "        # Fall back to standard algorithm if AI is not available or fails\n",
    "        recommended_pricing = {}\n",
    "        for vc, base_price in current_pricing.items():\n",
    "            if congestion_level > 0.7:  # High congestion: increase up to 20%\n",
    "                factor = 1.0 + (congestion_level - 0.7) * (0.2 / 0.3)\n",
    "            elif congestion_level < 0.3:  # Low congestion: decrease up to 10%\n",
    "                factor = 1.0 - (0.3 - congestion_level) * (0.1 / 0.3)\n",
    "            else:\n",
    "                factor = 1.0\n",
    "            recommended_pricing[vc] = round(base_price * factor, 2)\n",
    "        \n",
    "        # Calculate expected impact\n",
    "        if sum(current_pricing.values()) > 0:\n",
    "            revenue_change = (sum(recommended_pricing.values()) - sum(current_pricing.values())) / sum(current_pricing.values()) * 100\n",
    "        else:\n",
    "            revenue_change = 0\n",
    "            \n",
    "        traffic_reduction = 5 * (congestion_level - 0.5) if congestion_level > 0.5 else 0\n",
    "        \n",
    "        # Create recommendations output\n",
    "        recommendations = {\n",
    "            \"plaza\": plaza,\n",
    "            \"hour\": hour,\n",
    "            \"congestion_level\": float(congestion_level),\n",
    "            \"current_pricing\": current_pricing,\n",
    "            \"recommended_pricing\": recommended_pricing,\n",
    "            \"expected_impact\": {\n",
    "                \"revenue_change\": f\"{revenue_change:.2f}%\",\n",
    "                \"expected_traffic_reduction\": f\"{traffic_reduction:.2f}%\"\n",
    "            },\n",
    "            \"ai_enhanced\": False,\n",
    "            \"recommendation_timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _get_ai_pricing_recommendations(self, plaza, hour, congestion_level, current_pricing, historical):\n",
    "        \"\"\"Use OpenAI to generate enhanced dynamic pricing recommendations.\"\"\"\n",
    "        try:\n",
    "            # Get time context (day of week, etc.)\n",
    "            now = datetime.now()\n",
    "            day_of_week = now.strftime(\"%A\")\n",
    "            \n",
    "            # Prepare context for the AI\n",
    "            context = {\n",
    "                \"plaza\": plaza,\n",
    "                \"hour\": hour,\n",
    "                \"day_of_week\": day_of_week,\n",
    "                \"congestion_level\": congestion_level,\n",
    "                \"current_pricing\": current_pricing,\n",
    "                \"historical_data\": {\n",
    "                    \"avg_traffic\": historical['avg_traffic'],\n",
    "                    \"vehicle_distribution\": historical['vehicle_distribution'],\n",
    "                },\n",
    "                \"adjacent_hours_context\": self._get_adjacent_hours_data(plaza, hour)\n",
    "            }\n",
    "            \n",
    "            # Get AI recommendation\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"\n",
    "                    You are an AI pricing optimization specialist for toll plaza management.\n",
    "                    Analyze the provided data and recommend optimal dynamic pricing strategies.\n",
    "                    Your response should be a valid JSON object with recommended prices and \n",
    "                    expected impact analysis. Consider congestion levels, traffic patterns,\n",
    "                    vehicle types, and time-of-day factors. Apply economic principles of\n",
    "                    demand elasticity and peak-load pricing.\n",
    "                    \"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                    Provide dynamic pricing recommendations for the following toll plaza situation:\n",
    "                    {json.dumps(context, indent=2)}\n",
    "                    \n",
    "                    Return a JSON with these fields:\n",
    "                    1. recommended_pricing: object with vehicle class codes as keys and recommended prices as values\n",
    "                    2. expected_impact: object with revenue_change (%) and expected_traffic_reduction (%) \n",
    "                    3. pricing_strategy: string describing the recommended strategy\n",
    "                    4. optimization_notes: array of key insights about this pricing strategy\n",
    "                    \n",
    "                    The pricing should optimize for both revenue and traffic flow, considering the\n",
    "                    time of day, congestion level, and vehicle types.\n",
    "                    \"\"\"} \n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Extract and parse recommendation\n",
    "            ai_recommendation = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Format the expected impact values\n",
    "            expected_impact = ai_recommendation.get(\"expected_impact\", {})\n",
    "            if isinstance(expected_impact, dict):\n",
    "                for key, value in expected_impact.items():\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        expected_impact[key] = f\"{value:.2f}%\"\n",
    "            \n",
    "            # Create the complete recommendation to return\n",
    "            recommendation = {\n",
    "                \"plaza\": plaza,\n",
    "                \"hour\": hour,\n",
    "                \"congestion_level\": float(congestion_level),\n",
    "                \"current_pricing\": current_pricing,\n",
    "                \"recommended_pricing\": ai_recommendation.get(\"recommended_pricing\", {}),\n",
    "                \"expected_impact\": expected_impact,\n",
    "                \"pricing_strategy\": ai_recommendation.get(\"pricing_strategy\", \"\"),\n",
    "                \"optimization_notes\": ai_recommendation.get(\"optimization_notes\", []),\n",
    "                \"ai_enhanced\": True,\n",
    "                \"recommendation_timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            return recommendation\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error getting AI pricing recommendations: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def _get_adjacent_hours_data(self, plaza, hour):\n",
    "        \"\"\"Get data for hours before and after the target hour for context.\"\"\"\n",
    "        adjacent_data = {}\n",
    "        \n",
    "        # Previous hour\n",
    "        prev_hour = (hour - 1) % 24\n",
    "        if plaza in self.historical_patterns and prev_hour in self.historical_patterns[plaza]:\n",
    "            adjacent_data[\"previous_hour\"] = {\n",
    "                \"hour\": prev_hour,\n",
    "                \"avg_traffic\": self.historical_patterns[plaza][prev_hour]['avg_traffic']\n",
    "            }\n",
    "        \n",
    "        # Next hour\n",
    "        next_hour = (hour + 1) % 24\n",
    "        if plaza in self.historical_patterns and next_hour in self.historical_patterns[plaza]:\n",
    "            adjacent_data[\"next_hour\"] = {\n",
    "                \"hour\": next_hour,\n",
    "                \"avg_traffic\": self.historical_patterns[plaza][next_hour]['avg_traffic']\n",
    "            }\n",
    "            \n",
    "        return adjacent_data\n",
    "    \n",
    "    def visualize_lane_recommendations(self, plaza: str, hour: int) -> Dict[str, Any]:\n",
    "        \"\"\"Create visualization data for the lane recommendations.\"\"\"\n",
    "        recommendations = self.get_lane_recommendations(plaza, hour)\n",
    "        if \"error\" in recommendations:\n",
    "            return {\"error\": recommendations[\"error\"]}\n",
    "        \n",
    "        # Create enhanced visualization data\n",
    "        viz_data = {\n",
    "            \"plaza\": plaza,\n",
    "            \"hour\": hour,\n",
    "            \"lane_allocation\": {\n",
    "                \"lanes\": [lane[\"lane\"] for lane in recommendations[\"recommended_lanes\"]],\n",
    "                \"roles\": [lane[\"role\"] for lane in recommendations[\"recommended_lanes\"]],\n",
    "                \"volumes\": [lane[\"expected_volume\"] for lane in recommendations[\"recommended_lanes\"]],\n",
    "                \"processing_times\": [lane[\"processing_time\"] for lane in recommendations[\"recommended_lanes\"]]\n",
    "            },\n",
    "            \"vehicle_distribution\": recommendations[\"vehicle_distribution\"],\n",
    "            \"ai_enhanced\": recommendations.get(\"ai_enhanced\", False)\n",
    "        }\n",
    "        \n",
    "        # Add historical comparison\n",
    "        if plaza in self.historical_patterns and hour in self.historical_patterns[plaza]:\n",
    "            historical = self.historical_patterns[plaza][hour]\n",
    "            viz_data[\"historical_comparison\"] = {\n",
    "                \"avg_traffic\": historical['avg_traffic'],\n",
    "                \"expected_traffic\": recommendations[\"expected_traffic\"],\n",
    "                \"traffic_difference_percent\": ((recommendations[\"expected_traffic\"] - historical['avg_traffic']) / \n",
    "                                              historical['avg_traffic'] * 100) if historical['avg_traffic'] > 0 else 0\n",
    "            }\n",
    "        \n",
    "        return viz_data\n",
    "    \n",
    "    def get_optimization_insights(self, plaza: str) -> Dict[str, Any]:\n",
    "        \"\"\"Generate AI insights about optimization opportunities for a plaza.\"\"\"\n",
    "        if not self.client:\n",
    "            return {\"error\": \"OpenAI API key not configured for insights generation\"}\n",
    "            \n",
    "        try:\n",
    "            plaza_data = self.df[self.df['merchant_name'] == plaza]\n",
    "            if plaza_data.empty:\n",
    "                return {\"error\": f\"No data available for plaza {plaza}\"}\n",
    "                \n",
    "            # Create a summary of plaza operations\n",
    "            summary = {\n",
    "                \"plaza\": plaza,\n",
    "                \"total_transactions\": len(plaza_data),\n",
    "                \"lanes\": self.plaza_lanes.get(plaza, []),\n",
    "                \"avg_processing_time\": float(plaza_data['inn_rr_time_sec'].mean()),\n",
    "                \"peak_hours\": self._get_peak_hours(plaza_data),\n",
    "                \"vehicle_type_distribution\": dict(plaza_data['vehicle_class_code'].value_counts(normalize=True)),\n",
    "                \"commercial_ratio\": float(plaza_data['vehicle_comvehicle'].replace(\n",
    "                    {'F': 0, 'T': 1}).mean()) if 'vehicle_comvehicle' in plaza_data.columns else 0.3\n",
    "            }\n",
    "            \n",
    "            # Get lane efficiency data\n",
    "            plaza_efficiency = self.lane_efficiency[self.lane_efficiency['plaza'] == plaza].copy()\n",
    "            lane_data = plaza_efficiency.sort_values('efficiency_score').to_dict(orient='records')\n",
    "            \n",
    "            # Get AI insights\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"\n",
    "                    You are an AI traffic optimization analyst specializing in toll plaza operations.\n",
    "                    Analyze the provided toll plaza data and identify optimization opportunities.\n",
    "                    Focus on traffic flow improvements, lane efficiency, staffing optimization,\n",
    "                    and revenue enhancement strategies. \n",
    "                    \"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                    Analyze this toll plaza data and provide optimization insights:\n",
    "                    \n",
    "                    Plaza Summary:\n",
    "                    {json.dumps(summary, indent=2)}\n",
    "                    \n",
    "                    Lane Efficiency Data:\n",
    "                    {json.dumps(lane_data, indent=2)}\n",
    "                    \n",
    "                    Return a JSON with these fields:\n",
    "                    1. key_findings: array of most important observations\n",
    "                    2. optimization_opportunities: array of specific actionable recommendations\n",
    "                    3. projected_benefits: object with expected improvements in processing_time, revenue, and customer_satisfaction\n",
    "                    4. implementation_difficulty: ranking of each optimization opportunity (1-5 scale, 5 being most difficult)\n",
    "                    \"\"\"} \n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Extract and parse insights\n",
    "            insights = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Add metadata\n",
    "            insights[\"plaza\"] = plaza\n",
    "            insights[\"analysis_timestamp\"] = datetime.now().isoformat()\n",
    "            insights[\"data_analyzed\"] = {\n",
    "                \"transactions\": len(plaza_data),\n",
    "                \"time_period\": f\"{plaza_data['initiated_time'].min()} to {plaza_data['initiated_time'].max()}\"\n",
    "            }\n",
    "            \n",
    "            return insights\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error generating AI insights: {str(e)}\")\n",
    "            return {\"error\": f\"Failed to generate insights: {str(e)}\"}\n",
    "    \n",
    "    def _get_peak_hours(self, plaza_data):\n",
    "        \"\"\"Identify peak hours for a plaza.\"\"\"\n",
    "        hourly_counts = plaza_data.groupby(plaza_data['initiated_time'].dt.hour).size()\n",
    "        top_hours = hourly_counts.nlargest(3)\n",
    "        return [{\"hour\": int(hour), \"volume\": int(count)} for hour, count in top_hours.items()]\n",
    "    \n",
    "    def simulate_optimization_impact(self, plaza: str, recommendations: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Simulate the impact of implementing lane and pricing recommendations.\"\"\"\n",
    "        if not self.client:\n",
    "            return {\"error\": \"OpenAI API key not configured for simulation\"}\n",
    "            \n",
    "        try:\n",
    "            # Extract lane and pricing recommendations\n",
    "            lane_recommendations = recommendations.get(\"lane_recommendations\", {})\n",
    "            pricing_recommendations = recommendations.get(\"pricing_recommendations\", {})\n",
    "            \n",
    "            # Create simulation context\n",
    "            context = {\n",
    "                \"plaza\": plaza,\n",
    "                \"current_operations\": {\n",
    "                    \"avg_processing_time\": float(self.df[self.df['merchant_name'] == plaza]['inn_rr_time_sec'].mean()),\n",
    "                    \"lanes\": len(self.plaza_lanes.get(plaza, [])),\n",
    "                    \"pricing\": pricing_recommendations.get(\"current_pricing\", {})\n",
    "                },\n",
    "                \"recommended_operations\": {\n",
    "                    \"lane_allocation\": lane_recommendations.get(\"recommended_lanes\", []),\n",
    "                    \"pricing\": pricing_recommendations.get(\"recommended_pricing\", {})\n",
    "                },\n",
    "                \"traffic_volume\": lane_recommendations.get(\"expected_traffic\", 0),\n",
    "                \"congestion_level\": pricing_recommendations.get(\"congestion_level\", 0)\n",
    "            }\n",
    "            \n",
    "            # Get AI simulation\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"\n",
    "                    You are an AI traffic simulation expert specializing in toll plaza operations.\n",
    "                    Simulate the impact of implementing the recommended optimizations.\n",
    "                    Your simulation should estimate improvements in processing time, revenue,\n",
    "                    customer satisfaction, and overall throughput based on traffic engineering principles.\n",
    "                    \"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                    Simulate the impact of implementing these recommendations for {plaza} toll plaza:\n",
    "                    {json.dumps(context, indent=2)}\n",
    "                    \n",
    "                    Return a JSON with these fields:\n",
    "                    1. estimated_improvements: object with percentage improvements in various metrics\n",
    "                    2. estimated_roi: return on investment calculation \n",
    "                    3. implementation_timeline: estimated time to realize full benefits\n",
    "                    4. risk_factors: potential issues that could impact success\n",
    "                    5. success_factors: key elements needed for successful implementation\n",
    "                    \"\"\"} \n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Extract and parse simulation\n",
    "            simulation = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Add metadata\n",
    "            simulation[\"plaza\"] = plaza\n",
    "            simulation[\"simulation_timestamp\"] = datetime.now().isoformat()\n",
    "            simulation[\"simulation_type\"] = \"ai_predictive_model\"\n",
    "            \n",
    "            return simulation\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error simulating optimization impact: {str(e)}\")\n",
    "            return {\"error\": f\"Failed to simulate impact: {str(e)}\"}\n",
    "\n",
    "# Example usage:\n",
    "# Initialize enhanced lane optimization system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_usage(df):\n",
    "    print(\"\\n2. ENHANCED LANE OPTIMIZATION SYSTEM WITH OPENAI\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Initialize with your OpenAI API key or set OPENAI_API_KEY environment variable\n",
    "    lane_optimizer = EnhancedLaneOptimizationSystem(df, openai_api_key='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')\n",
    "    \n",
    "    # Get a sample plaza and hour\n",
    "    plaza_example = df['merchant_name'].value_counts().index[0]  # Most common plaza\n",
    "    hour_example = 8  # Example hour\n",
    "    \n",
    "    # Get lane recommendations with AI enhancement\n",
    "    lane_recommendations = lane_optimizer.get_lane_recommendations(\n",
    "        plaza_example, hour_example, use_ai=True)\n",
    "    print(f\"Lane recommendations for {plaza_example} at {hour_example}:00:\")\n",
    "    print(json.dumps(lane_recommendations, indent=2))\n",
    "    \n",
    "    # Get dynamic pricing recommendations with AI enhancement\n",
    "    pricing_recommendations = lane_optimizer.get_dynamic_pricing_recommendations(\n",
    "        plaza_example, hour_example, use_ai=True)\n",
    "    print(f\"\\nDynamic pricing recommendations for {plaza_example} at {hour_example}:00:\")\n",
    "    print(json.dumps(pricing_recommendations, indent=2))\n",
    "    \n",
    "    # Get AI-generated optimization insights\n",
    "    insights = lane_optimizer.get_optimization_insights(plaza_example)\n",
    "    print(f\"\\nAI-generated optimization insights for {plaza_example}:\")\n",
    "    print(json.dumps(insights, indent=2))\n",
    "    \n",
    "    # Simulate the impact of implementing the recommendations\n",
    "    simulation = lane_optimizer.simulate_optimization_impact(\n",
    "        plaza_example, {\n",
    "            \"lane_recommendations\": lane_recommendations,\n",
    "            \"pricing_recommendations\": pricing_recommendations\n",
    "        })\n",
    "    print(f\"\\nSimulated impact of optimization for {plaza_example}:\")\n",
    "    print(json.dumps(simulation, indent=2))\n",
    "\n",
    "# Run the example (uncomment to execute)\n",
    "example_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. AUTOMATED INSIGHTS GENERATOR\n",
      "--------------------------------------------------\n",
      "Generating automated insights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-20 12:15:17,947 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insights Narrative (excerpt):\n",
      "### Bullet-Point Summary\n",
      "\n",
      "- **Traffic Patterns**:\n",
      "  - Peak traffic occurs at 5 PM, with a significant drop during off-peak hours at 3 AM.\n",
      "  - Devanahalli Toll Plaza is the busiest, while Magadi Road (P6) Plaza is the quietest.\n",
      "  - Evening traffic is slightly less than morning traffic, with a ratio of 1.27:1.\n",
      "  - Night traffic accounts for approximately 25.3% of total traffic.\n",
      "\n",
      "- **Vehicle Insights**:\n",
      "  - VC4 is the most common vehicle class, representing 68.6% of traffic.\n",
      "  - Commercial vehicles make up 34.4% of the total vehicle count.\n",
      "  - VC4 also generates the most revenue, amounting to 46.3% of total revenue.\n",
      "\n",
      "- **Operational Efficiency**:\n",
      "  - Average processing time across plazas is approximately 1005 seconds.\n",
      "  - Bangalore-Nelamangala Plaza is the fastest in processing, while Magadi Road (P6) Plaza is the slowest.\n",
      "  - VC6 vehicles have the fastest processing time, while VC15 vehicles are the slowest.\n",
      "\n",
      "- **Revenue Insights**:\n",
      "  - Devanahalli Toll Plaza leads in revenue, contributing 34.3% of total revenue.\n",
      "  - The average transaction amount is about 82.72, with the highest average revenue at Hosur Road (P1) Toll.\n",
      "  - Peak revenue is generated at 11 PM.\n",
      "\n",
      "### Detailed Analysis\n",
      "\n",
      "#### Traffic Patterns\n",
      "The data reveals distinct traffic patterns with peak activity at 5 PM, suggesting high commuter traffic during the evening rush hour. This insight can guide toll plaza operators to allocate resources, such as staffing and lane management, to accommodate the increased volume. The significant traffic drop at 3 AM indicates a potential window for maintenance activities with minimal disruption. The Devanahalli Toll Plaza's status as the busiest indicates its strategic importance in traffic flow and revenue generation, warranting focused operational enhancements.\n",
      "\n",
      "#### Vehicle Insights\n",
      "VC4 vehicles dominate the traffic landscape, accounting for the majority of the vehicle mix and revenue. This suggests a reliance on passenger vehicles, which can inform pricing strategies and service offerings tailored to this demographic. The notable presence of commercial vehicles highlights the importance of maintaining efficient processing to support logistics operations.\n",
      "\n",
      "#### Operational Efficiency\n",
      "The disparity in processing times between the fastest and slowest plazas underscores the need for operational improvements at Magadi Road (P6) Plaza. Streamlining processes or upgrading infrastructure here could significantly enhance throughput and customer satisfaction. The efficiency of VC6 vehicles suggests potential best practices that could be applied to other vehicle classes to improve overall processing times.\n",
      "\n",
      "#### Revenue Insights\n",
      "With Devanahalli Toll Plaza generating a substantial portion of total revenue, ensuring its operational excellence is crucial. The high average transaction amount at Hosur Road (P1) Toll indicates a potential for premium services or pricing models that could be explored further. The peak revenue hour at 11 PM suggests that late-night traffic is a valuable segment, possibly driven by long-haul transporters, which can be targeted with specific marketing strategies or loyalty programs.\n",
      "\n",
      "### Actionable Recommendations\n",
      "\n",
      "1. **Resource Allocation**: Increase staffing and open additional lanes during peak hours, particularly at Devanahalli Toll Plaza, to manage high traffic volumes efficiently.\n",
      "   \n",
      "2. **Operational Improvements**: Conduct a detailed review of processes at Magadi Road (P6) Plaza to identify bottlenecks and implement technology upgrades or process optimizations.\n",
      "\n",
      "3. **Pricing Strategies**: Consider tiered pricing models or loyalty programs targeting VC4 and commercial vehicles to maximize revenue.\n",
      "\n",
      "4. **Maintenance Scheduling**: Utilize off-peak hours, especially around 3 AM, for maintenance activities to minimize impact on traffic flow.\n",
      "\n",
      "5. **Marketing Initiatives**: Develop targeted marketing campaigns for late-night commuters, highlighting the benefits of using toll roads during these hours.\n",
      "\n",
      "By implementing these strategies, toll plaza operators can enhance operational efficiency, optimize revenue, and improve overall user experience.\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 3. AUTOMATED INSIGHTS GENERATOR\n",
    "# =============================================================================\n",
    "print(\"\\n3. AUTOMATED INSIGHTS GENERATOR\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "class AutomatedInsightsGenerator:\n",
    "    def __init__(self, data, openai_api_key=None):\n",
    "        self.df = data\n",
    "        self.client = None\n",
    "        if openai_api_key:\n",
    "            try:\n",
    "                self.client = OpenAI(api_key=openai_api_key)\n",
    "            except Exception as e:\n",
    "                print(f\"Error initializing OpenAI client: {e}\")\n",
    "                print(\"Automated insights will be generated without OpenAI.\")\n",
    "    \n",
    "    def _get_basic_stats(self) -> Dict[str, Any]:\n",
    "        stats = {\n",
    "            \"total_transactions\": len(self.df),\n",
    "            \"total_plazas\": self.df['merchant_name'].nunique(),\n",
    "            \"total_vehicles\": self.df['vehicle_regn_number'].nunique(),\n",
    "            \"total_revenue\": float(self.df['txn_amount'].sum()),\n",
    "            \"avg_transaction_amount\": float(self.df['txn_amount'].mean()),\n",
    "            \"busiest_plaza\": self.df['merchant_name'].value_counts().index[0],\n",
    "            \"busiest_hour\": self.df.groupby(self.df['initiated_time'].dt.hour).size().idxmax(),\n",
    "            \"most_common_vehicle_type\": self.df['vehicle_class_code'].value_counts().index[0]\n",
    "        }\n",
    "        return stats\n",
    "    \n",
    "    def _get_traffic_insights(self) -> Dict[str, Any]:\n",
    "        hourly_traffic = self.df.groupby(self.df['initiated_time'].dt.hour).size()\n",
    "        peak_hour = hourly_traffic.idxmax()\n",
    "        off_peak_hour = hourly_traffic.idxmin()\n",
    "        morning_traffic = hourly_traffic.loc[6:12].sum()\n",
    "        evening_traffic = hourly_traffic.loc[16:20].sum()\n",
    "        night_traffic = hourly_traffic.loc[[*range(0, 6), *range(21, 24)]].sum()\n",
    "        plaza_traffic = self.df['merchant_name'].value_counts()\n",
    "        busiest_plaza = plaza_traffic.index[0]\n",
    "        quietest_plaza = plaza_traffic.index[-1]\n",
    "        direction_traffic = self.df['direction'].value_counts(normalize=True)\n",
    "        main_direction = direction_traffic.index[0]\n",
    "        main_direction_pct = float(direction_traffic.iloc[0] * 100)\n",
    "        \n",
    "        insights = {\n",
    "            \"peak_hour\": int(peak_hour),\n",
    "            \"peak_hour_traffic\": int(hourly_traffic[peak_hour]),\n",
    "            \"off_peak_hour\": int(off_peak_hour),\n",
    "            \"off_peak_hour_traffic\": int(hourly_traffic[off_peak_hour]),\n",
    "            \"peak_to_offpeak_ratio\": float(hourly_traffic[peak_hour] / hourly_traffic[off_peak_hour]),\n",
    "            \"morning_vs_evening\": {\n",
    "                \"morning_traffic\": int(morning_traffic),\n",
    "                \"evening_traffic\": int(evening_traffic),\n",
    "                \"ratio\": float(morning_traffic / evening_traffic) if evening_traffic > 0 else float('inf')\n",
    "            },\n",
    "            \"night_traffic_percentage\": float(night_traffic / hourly_traffic.sum() * 100),\n",
    "            \"busiest_plaza\": busiest_plaza,\n",
    "            \"busiest_plaza_transactions\": int(plaza_traffic[busiest_plaza]),\n",
    "            \"quietest_plaza\": quietest_plaza,\n",
    "            \"quietest_plaza_transactions\": int(plaza_traffic[quietest_plaza]),\n",
    "            \"main_travel_direction\": main_direction,\n",
    "            \"main_direction_percentage\": main_direction_pct\n",
    "        }\n",
    "        return insights\n",
    "    \n",
    "    def _get_vehicle_insights(self) -> Dict[str, Any]:\n",
    "        vehicle_dist = self.df['vehicle_class_code'].value_counts(normalize=True)\n",
    "        \n",
    "        if 'vehicle_comvehicle' in self.df.columns:\n",
    "            # Convert the column to numeric: 'F' -> 0, 'T' -> 1, non-convertible values become NaN\n",
    "            vc_series = pd.to_numeric(\n",
    "                self.df['vehicle_comvehicle'].replace({'F': 0, 'T': 1}),\n",
    "                errors='coerce'\n",
    "            )\n",
    "            commercial_pct = float(vc_series.mean() * 100)\n",
    "        else:\n",
    "            commercial_classes = ['VC5', 'VC6', 'VC7', 'VC8', 'VC10', 'VC11', 'VC12', 'VC13', 'VC14', 'VC15', 'VC16', 'VC17', 'VC20']\n",
    "            commercial_pct = float(self.df['vehicle_class_code'].isin(commercial_classes).mean() * 100)\n",
    "        \n",
    "        revenue_by_class = self.df.groupby('vehicle_class_code')['txn_amount'].sum()\n",
    "        top_revenue_class = revenue_by_class.idxmax()\n",
    "        avg_by_class = self.df.groupby('vehicle_class_code')['txn_amount'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        insights = {\n",
    "            \"top_vehicle_class\": vehicle_dist.index[0],\n",
    "            \"top_vehicle_class_percentage\": float(vehicle_dist.iloc[0] * 100),\n",
    "            \"commercial_vehicle_percentage\": commercial_pct,\n",
    "            \"top_revenue_vehicle_class\": top_revenue_class,\n",
    "            \"top_revenue_vehicle_class_amount\": float(revenue_by_class[top_revenue_class]),\n",
    "            \"highest_fare_vehicle_class\": avg_by_class.index[0],\n",
    "            \"highest_fare_amount\": float(avg_by_class.iloc[0]),\n",
    "            \"vehicle_class_distribution\": {k: float(v * 100) for k, v in vehicle_dist.items()}\n",
    "        }\n",
    "        return insights\n",
    "\n",
    "    \n",
    "    def _get_operational_insights(self) -> Dict[str, Any]:\n",
    "        avg_processing = float(self.df['inn_rr_time_sec'].mean())\n",
    "        plaza_processing = self.df.groupby('merchant_name')['inn_rr_time_sec'].mean().sort_values()\n",
    "        fastest_plaza = plaza_processing.index[0]\n",
    "        slowest_plaza = plaza_processing.index[-1]\n",
    "        class_processing = self.df.groupby('vehicle_class_code')['inn_rr_time_sec'].mean().sort_values()\n",
    "        fastest_class = class_processing.index[0]\n",
    "        slowest_class = class_processing.index[-1]\n",
    "        hour_processing = self.df.groupby(self.df['initiated_time'].dt.hour)['inn_rr_time_sec'].mean()\n",
    "        fastest_hour = hour_processing.idxmin()\n",
    "        slowest_hour = hour_processing.idxmax()\n",
    "        \n",
    "        insights = {\n",
    "            \"average_processing_time\": avg_processing,\n",
    "            \"fastest_plaza\": fastest_plaza,\n",
    "            \"fastest_plaza_time\": float(plaza_processing[fastest_plaza]),\n",
    "            \"slowest_plaza\": slowest_plaza,\n",
    "            \"slowest_plaza_time\": float(plaza_processing[slowest_plaza]),\n",
    "            \"fastest_vehicle_class\": fastest_class,\n",
    "            \"fastest_vehicle_class_time\": float(class_processing[fastest_class]),\n",
    "            \"slowest_vehicle_class\": slowest_class,\n",
    "            \"slowest_vehicle_class_time\": float(class_processing[slowest_class]),\n",
    "            \"fastest_hour\": int(fastest_hour),\n",
    "            \"fastest_hour_time\": float(hour_processing[fastest_hour]),\n",
    "            \"slowest_hour\": int(slowest_hour),\n",
    "            \"slowest_hour_time\": float(hour_processing[slowest_hour])\n",
    "        }\n",
    "        return insights\n",
    "    \n",
    "    def _get_revenue_insights(self) -> Dict[str, Any]:\n",
    "        hourly_revenue = self.df.groupby(self.df['initiated_time'].dt.hour)['txn_amount'].sum()\n",
    "        peak_revenue_hour = hourly_revenue.idxmax()\n",
    "        plaza_revenue = self.df.groupby('merchant_name')['txn_amount'].sum().sort_values(ascending=False)\n",
    "        top_revenue_plaza = plaza_revenue.index[0]\n",
    "        plaza_avg_revenue = self.df.groupby('merchant_name')['txn_amount'].mean().sort_values(ascending=False)\n",
    "        highest_avg_plaza = plaza_avg_revenue.index[0]\n",
    "        \n",
    "        insights = {\n",
    "            \"total_daily_revenue\": float(self.df['txn_amount'].sum()),\n",
    "            \"average_transaction_amount\": float(self.df['txn_amount'].mean()),\n",
    "            \"median_transaction_amount\": float(self.df['txn_amount'].median()),\n",
    "            \"peak_revenue_hour\": int(peak_revenue_hour),\n",
    "            \"peak_hour_revenue\": float(hourly_revenue[peak_revenue_hour]),\n",
    "            \"top_revenue_plaza\": top_revenue_plaza,\n",
    "            \"top_plaza_revenue\": float(plaza_revenue[top_revenue_plaza]),\n",
    "            \"top_plaza_revenue_percentage\": float(plaza_revenue[top_revenue_plaza] / plaza_revenue.sum() * 100),\n",
    "            \"highest_average_revenue_plaza\": highest_avg_plaza,\n",
    "            \"highest_average_amount\": float(plaza_avg_revenue[highest_avg_plaza])\n",
    "        }\n",
    "        return insights\n",
    "    \n",
    "    def generate_natural_language_insights(self, data_summary: Dict[str, Any]) -> str:\n",
    "        if self.client:\n",
    "            try:\n",
    "                prompt = f\"\"\"\n",
    "                You are a transportation analytics expert. Based on the following toll plaza data insights, \n",
    "                generate a comprehensive analysis that highlights key patterns, anomalies, and actionable \n",
    "                recommendations for toll plaza operators. Format your response as a bullet-point summary\n",
    "                followed by paragraphs of detailed analysis. Focus on actionable insights.\n",
    "                \n",
    "                DATA INSIGHTS:\n",
    "                {data_summary}\n",
    "                \"\"\"\n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-4o\",\n",
    "                    messages=[{\"role\": \"system\", \"content\": \"You are a toll plaza analytics expert.\"},\n",
    "                              {\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=0.5\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                print(f\"Error using OpenAI: {e}\")\n",
    "                return self._generate_fallback_insights(data_summary)\n",
    "        else:\n",
    "            return self._generate_fallback_insights(data_summary)\n",
    "    \n",
    "    def _generate_fallback_insights(self, data_summary: Dict[str, Any]) -> str:\n",
    "        traffic = data_summary.get(\"traffic_insights\", {})\n",
    "        vehicle = data_summary.get(\"vehicle_insights\", {})\n",
    "        operation = data_summary.get(\"operational_insights\", {})\n",
    "        revenue = data_summary.get(\"revenue_insights\", {})\n",
    "        \n",
    "        insights = f\"\"\"\n",
    "        # Toll Plaza Analytics Insights\n",
    "\n",
    "        ## Key Highlights\n",
    "        * Total transactions: {data_summary.get('basic_stats', {}).get('total_transactions', 'N/A')}\n",
    "        * Total revenue: {data_summary.get('basic_stats', {}).get('total_revenue', 'N/A'):,.2f}\n",
    "        * Peak hour: {traffic.get('peak_hour', 'N/A')}:00 with {traffic.get('peak_hour_traffic', 'N/A')} transactions\n",
    "        * Busiest plaza: {traffic.get('busiest_plaza', 'N/A')} with {traffic.get('busiest_plaza_transactions', 'N/A')} transactions\n",
    "        \n",
    "        ## Traffic Patterns\n",
    "        The peak hour ({traffic.get('peak_hour', 'N/A')}:00) has {traffic.get('peak_to_offpeak_ratio', 'N/A'):.1f}x more traffic than the off-peak hour ({traffic.get('off_peak_hour', 'N/A')}:00). \n",
    "        Morning traffic is {traffic.get('morning_vs_evening', {}).get('ratio', 'N/A'):.2f}x the evening traffic.\n",
    "        \n",
    "        ## Vehicle Distribution\n",
    "        {vehicle.get('commercial_vehicle_percentage', 'N/A'):.1f}% of vehicles are commercial, with {vehicle.get('top_vehicle_class', 'N/A')} being the most common type.\n",
    "        The {vehicle.get('top_revenue_vehicle_class', 'N/A')} class generates the most revenue at {vehicle.get('top_revenue_vehicle_class_amount', 'N/A'):,.2f}.\n",
    "        \n",
    "        ## Operational Efficiency\n",
    "        Average processing time is {operation.get('average_processing_time', 'N/A'):.2f} seconds.\n",
    "        {operation.get('fastest_plaza', 'N/A')} is the most efficient plaza at {operation.get('fastest_plaza_time', 'N/A'):.2f}s.\n",
    "        \n",
    "        ## Revenue Insights\n",
    "        Total daily revenue is {revenue.get('total_daily_revenue', 'N/A'):,.2f} with an average transaction of {revenue.get('average_transaction_amount', 'N/A'):.2f}.\n",
    "        Peak revenue hour is {revenue.get('peak_revenue_hour', 'N/A')}:00, generating {revenue.get('peak_hour_revenue', 'N/A'):,.2f}.\n",
    "        \n",
    "        ## Recommendations\n",
    "        1. Optimize lane allocation during peak hours.\n",
    "        2. Consider dynamic pricing to balance traffic.\n",
    "        3. Improve processing times at less efficient plazas.\n",
    "        4. Target revenue optimization for {vehicle.get('top_revenue_vehicle_class', 'N/A')} vehicles.\n",
    "        \"\"\"\n",
    "        return insights\n",
    "    \n",
    "    def generate_insights_report(self) -> Dict[str, Any]:\n",
    "        basic_stats = self._get_basic_stats()\n",
    "        traffic_insights = self._get_traffic_insights()\n",
    "        vehicle_insights = self._get_vehicle_insights()\n",
    "        operational_insights = self._get_operational_insights()\n",
    "        revenue_insights = self._get_revenue_insights()\n",
    "        \n",
    "        data_summary = {\n",
    "            \"basic_stats\": basic_stats,\n",
    "            \"traffic_insights\": traffic_insights,\n",
    "            \"vehicle_insights\": vehicle_insights,\n",
    "            \"operational_insights\": operational_insights,\n",
    "            \"revenue_insights\": revenue_insights\n",
    "        }\n",
    "        \n",
    "        narrative = self.generate_natural_language_insights(data_summary)\n",
    "        \n",
    "        report = {\n",
    "            \"summary\": data_summary,\n",
    "            \"narrative\": narrative,\n",
    "            \"generated_at\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"data_date\": self.df['initiated_time'].dt.date.min().strftime(\"%Y-%m-%d\")\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def generate_plaza_insights(self, plaza_name: str) -> Dict[str, Any]:\n",
    "        plaza_data = self.df[self.df['merchant_name'] == plaza_name]\n",
    "        if plaza_data.empty:\n",
    "            return {\"error\": f\"No data found for plaza {plaza_name}\"}\n",
    "        \n",
    "        temp_generator = AutomatedInsightsGenerator(plaza_data, None)\n",
    "        return temp_generator.generate_insights_report()\n",
    "\n",
    "# Check for OpenAI key (implement your own key handling)\n",
    "openai_key = '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'\n",
    "if not openai_key:\n",
    "    print(\"No OpenAI API key found. Using fallback insight generation.\")\n",
    "\n",
    "# Initialize insights generator\n",
    "insights_generator = AutomatedInsightsGenerator(df, openai_key)\n",
    "print(\"Generating automated insights...\")\n",
    "insights_report = insights_generator.generate_insights_report()\n",
    "print(\"\\nInsights Narrative (excerpt):\")\n",
    "narrative_excerpt = \"\\n\".join(insights_report[\"narrative\"].strip().split(\"\\n\"))\n",
    "print(narrative_excerpt + \"\\n...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m incidents\n\u001b[1;32m     62\u001b[0m app \u001b[38;5;241m=\u001b[39m Flask(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/preprocessed_tollplaza_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitiated_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitiated_time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     65\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_interval\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_interval\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/Paycrypt 1/paycrypt/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Paycrypt 1/paycrypt/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Paycrypt 1/paycrypt/.venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Desktop/Paycrypt 1/paycrypt/.venv/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from flask import Flask, jsonify\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def debug_dataframe(df):\n",
    "    logger.info(\"Debugging DataFrame...\")\n",
    "    logger.info(f\"Columns: {df.columns.tolist()}\")\n",
    "    logger.info(f\"Data types: {df.dtypes}\")\n",
    "    logger.info(f\"Missing values: {df.isna().sum()}\")\n",
    "    logger.info(f\"First few rows:\\n{df.head()}\")\n",
    "    df.columns = df.columns.str.strip()\n",
    "    return df\n",
    "\n",
    "class TollSkippingDetection:\n",
    "    def __init__(self, data):\n",
    "        self.df = debug_dataframe(data)  #  Ensure self.df is initialized\n",
    "        self.graph = self._build_route_graph()\n",
    "        self.expected_routes = self._identify_common_routes()\n",
    "        self.tag_routes = self._extract_vehicle_routes()\n",
    "\n",
    "    def _build_route_graph(self):\n",
    "        G = nx.DiGraph()\n",
    "        for _, group in self.df.groupby('tag_id'):\n",
    "            plazas = group.sort_values('initiated_time')['merchant_name'].tolist()\n",
    "            for i in range(len(plazas) - 1):\n",
    "                G.add_edge(plazas[i], plazas[i + 1], weight=G.get_edge_data(plazas[i], plazas[i + 1], {'weight': 0})['weight'] + 1)\n",
    "        return G\n",
    "\n",
    "    def _identify_common_routes(self):\n",
    "        common_routes = {}\n",
    "        for edge in self.graph.edges(data=True):\n",
    "            source, target, data = edge\n",
    "            common_routes[(source, target)] = list(nx.all_simple_paths(self.graph, source, target))  #  Convert generator to list\n",
    "        return common_routes\n",
    "\n",
    "    def _extract_vehicle_routes(self):\n",
    "        vehicle_routes = {}\n",
    "        for tag_id, group in self.df.groupby('tag_id'):\n",
    "            sorted_group = group.sort_values('initiated_time')\n",
    "            vehicle_routes[tag_id] = list(zip(sorted_group['merchant_name'], sorted_group['initiated_time']))\n",
    "        return vehicle_routes\n",
    "\n",
    "    def detect_potential_toll_skipping(self):\n",
    "        incidents = []\n",
    "        for tag_id, route in self.tag_routes.items():\n",
    "            for i in range(len(route) - 1):\n",
    "                source, target = route[i][0], route[i + 1][0]\n",
    "                if (source, target) in self.expected_routes and len(self.expected_routes[(source, target)]) > 2:\n",
    "                    incidents.append({\n",
    "                        \"tag_id\": tag_id,\n",
    "                        \"source_plaza\": source,\n",
    "                        \"target_plaza\": target,\n",
    "                        \"skipped_tolls\": len(self.expected_routes[(source, target)]) - 2,\n",
    "                        \"estimated_loss\": (len(self.expected_routes[(source, target)]) - 2) * 50\n",
    "                    })\n",
    "        return incidents\n",
    "\n",
    "app = Flask(__name__)\n",
    "df = pd.read_csv('data/preprocessed_tollplaza_data.csv')\n",
    "df['initiated_time'] = pd.to_datetime(df['initiated_time'])\n",
    "df['time_interval'] = pd.to_datetime(df['time_interval'])\n",
    "skipping_detector = TollSkippingDetection(df)\n",
    "skipping_report = skipping_detector.detect_potential_toll_skipping()\n",
    "\n",
    "@app.route('/api/toll-skipping', methods=['GET'])\n",
    "def get_toll_skipping():\n",
    "    return jsonify(skipping_report)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
